{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi\n",
    "\n",
    "We will modify vanilla Viterbi algorithm to tackle problem arising because of unknown words\n",
    "\n",
    "### Exploring Universal tag set\n",
    "1. Create Treebank dataset of NLTK with the 'universal' tagset\n",
    "   - Perform text and structure exploration\n",
    "2. Creating HMM model on the tagged data set.\n",
    "   - Calculating Emission Probabaility: P(observation|state)\n",
    "   - Calculating Transition Probability: P(state2|state1)\n",
    "\n",
    "\n",
    "### Develop Viterbi Heuristic\n",
    "1. POS Tagging Algorithm - HMM\n",
    "2. Developing algorithm for vanilla Viterbi Heuristic\n",
    "3. Checking accuracy on the test data set\n",
    "\n",
    "\n",
    "### Solve the problem of unknown words\n",
    "1. Modifying vanilla Viterbi Heuristic based on sound observation (First technique)\n",
    "2. Checking accuracy on the test data set of the first technique\n",
    "3. Modifying vanilla Viterbi Heuristic based on sound observation (Second technique)\n",
    "4. Checking accuracy on the test data set of the second technique\n",
    "\n",
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm\n",
    "\n",
    "Compare the tagging accuacies from the above techniques with vanilla Viterbi algorithm\n",
    "\n",
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by modifications\n",
    "\n",
    "1. Read the text file provided in this assignment and run it against different algorithms. \n",
    "2. List down the cases which were incorrectly tagged and then corrected by modified Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring Universal tag set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the universal tag set\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('61', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  (',', '.'),\n",
       "  ('will', 'VERB'),\n",
       "  ('join', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('board', 'NOUN'),\n",
       "  ('as', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('Nov.', 'NOUN'),\n",
       "  ('29', 'NUM'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NOUN'),\n",
       "  ('Vinken', 'NOUN'),\n",
       "  ('is', 'VERB'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Elsevier', 'NOUN'),\n",
       "  ('N.V.', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('Dutch', 'NOUN'),\n",
       "  ('publishing', 'VERB'),\n",
       "  ('group', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NOUN'),\n",
       "  ('Agnew', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('55', 'NUM'),\n",
       "  ('years', 'NOUN'),\n",
       "  ('old', 'ADJ'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('former', 'ADJ'),\n",
       "  ('chairman', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Consolidated', 'NOUN'),\n",
       "  ('Gold', 'NOUN'),\n",
       "  ('Fields', 'NOUN'),\n",
       "  ('PLC', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('was', 'VERB'),\n",
       "  ('named', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('a', 'DET'),\n",
       "  ('nonexecutive', 'ADJ'),\n",
       "  ('director', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('British', 'ADJ'),\n",
       "  ('industrial', 'ADJ'),\n",
       "  ('conglomerate', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first few tagged sentences\n",
    "nltk_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n",
      "[[('Over', 'ADP'), ('50', 'NUM'), ('witnesses', 'NOUN'), (',', '.'), ('mostly', 'ADV'), ('students', 'NOUN'), (',', '.'), ('were', 'VERB'), ('interviewed', 'VERB'), ('*-1', 'X'), ('.', '.')], [('When', 'ADV'), ('*', 'X'), ('referred', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('the', 'DET'), ('questions', 'NOUN'), ('that', 'DET'), ('*T*-107', 'X'), ('matched', 'VERB'), ('*T*-1', 'X'), (',', '.'), ('he', 'PRON'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('was', 'VERB'), ('coincidental', 'ADJ'), ('.', '.')], [('The', 'DET'), ('recent', 'ADJ'), ('cash', 'NOUN'), ('squeeze', 'NOUN'), ('at', 'ADP'), ('Campeau', 'NOUN'), ('Corp.', 'NOUN'), (',', '.'), ('First', 'NOUN'), ('Boston', 'NOUN'), (\"'s\", 'PRT'), ('most', 'ADJ'), ('lucrative', 'ADJ'), ('client', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('decade', 'NOUN'), (',', '.'), ('is', 'VERB'), ('proving', 'VERB'), ('costly', 'ADJ'), ('to', 'PRT'), ('First', 'NOUN'), ('Boston', 'NOUN'), ('because', 'ADP'), ('it', 'PRON'), ('arranged', 'VERB'), ('more', 'ADJ'), ('than', 'ADP'), ('$', '.'), ('3', 'NUM'), ('billion', 'NUM'), ('*U*', 'X'), ('of', 'ADP'), ('high-yield', 'ADJ'), (',', '.'), ('high-risk', 'ADJ'), ('junk', 'NOUN'), ('financings', 'NOUN'), ('for', 'ADP'), ('Campeau', 'NOUN'), ('units', 'NOUN'), ('.', '.')], [('In', 'ADP'), ('an', 'DET'), ('interview', 'NOUN'), (',', '.'), ('Mr.', 'NOUN'), ('Bernstein', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('his', 'PRON'), ('departure', 'NOUN'), ('``', '.'), ('evolved', 'VERB'), ('out', 'ADP'), ('of', 'ADP'), ('discussions', 'NOUN'), ('with', 'ADP'), ('Si', 'NOUN'), ('Newhouse', 'NOUN'), ('and', 'CONJ'), ('that', 'DET'), (\"'s\", 'VERB'), ('the', 'DET'), ('decision', 'NOUN'), ('0', 'X'), ('I', 'PRON'), ('reached', 'VERB'), ('*T*-1', 'X'), ('.', '.'), (\"''\", '.')], [('The', 'DET'), ('industrial', 'ADJ'), ('average', 'NOUN'), ('jumped', 'VERB'), ('more', 'ADV'), ('than', 'ADP'), ('41', 'NUM'), ('points', 'NOUN'), ('Tuesday', 'NOUN'), ('as', 'ADP'), ('speculators', 'NOUN'), ('rushed', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('buy', 'VERB'), ('shares', 'NOUN'), ('of', 'ADP'), ('potential', 'ADJ'), ('takeover', 'NOUN'), ('targets', 'NOUN'), ('.', '.')], [('A', 'DET'), ('driver', 'NOUN'), ('has', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('find', 'VERB'), ('something', 'NOUN'), ('0', 'X'), ('*', 'X'), ('to', 'PRT'), ('hang', 'VERB'), ('the', 'DET'), ('carrier', 'NOUN'), ('on', 'ADP'), ('*T*-2', 'X'), (',', '.'), ('so', 'ADP'), ('the', 'DET'), ('company', 'NOUN'), ('supplies', 'VERB'), ('a', 'DET'), ('window', 'NOUN'), ('hook', 'NOUN'), ('.', '.')], [('The', 'DET'), ('exchange', 'NOUN'), ('also', 'ADV'), ('said', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('30-point', 'ADJ'), ('circuit', 'NOUN'), ('breaker', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-212', 'X'), ('currently', 'ADV'), ('provides', 'VERB'), ('only', 'ADV'), ('a', 'DET'), ('one-hour', 'ADJ'), ('respite', 'NOUN'), ('during', 'ADP'), ('market', 'NOUN'), ('sell-offs', 'NOUN'), (',', '.'), ('will', 'VERB'), ('become', 'VERB'), ('the', 'DET'), ('maximum', 'NOUN'), ('one-day', 'ADJ'), ('limit', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('S&P', 'NOUN'), ('500', 'NUM'), ('stock-index', 'ADJ'), ('futures', 'NOUN'), ('contract', 'NOUN'), (';', '.'), ('the', 'DET'), ('one-day', 'ADJ'), ('limit', 'NOUN'), ('now', 'ADV'), ('is', 'VERB'), ('50', 'NUM'), ('index', 'NOUN'), ('points', 'NOUN'), ('.', '.')], [('In', 'ADP'), ('Richmond', 'NOUN'), (',', '.'), ('Ind.', 'NOUN'), (',', '.'), ('the', 'DET'), ('type', 'NOUN'), ('F', 'NOUN'), ('railing', 'NOUN'), ('is', 'VERB'), ('being', 'VERB'), ('used', 'VERB'), ('*-1', 'X'), ('*-2', 'X'), ('to', 'PRT'), ('replace', 'VERB'), ('arched', 'ADJ'), ('openings', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('G', 'NOUN'), ('Street', 'NOUN'), ('Bridge', 'NOUN'), ('.', '.')], [('William', 'NOUN'), ('G.', 'NOUN'), ('Kuhns', 'NOUN'), (',', '.'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('*RNR*-1', 'X'), ('and', 'CONJ'), ('chief', 'ADJ'), ('executive', 'ADJ'), ('officer', 'NOUN'), ('*RNR*-1', 'X'), ('of', 'ADP'), ('General', 'NOUN'), ('Public', 'NOUN'), ('Utilities', 'NOUN'), ('Corp.', 'NOUN'), (',', '.'), ('was', 'VERB'), ('elected', 'VERB'), ('*-2', 'X'), ('a', 'DET'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('maker', 'NOUN'), ('of', 'ADP'), ('industrial', 'ADJ'), ('and', 'CONJ'), ('construction', 'NOUN'), ('equipment', 'NOUN'), (',', '.'), ('*', 'X'), ('increasing', 'VERB'), ('board', 'NOUN'), ('membership', 'NOUN'), ('to', 'PRT'), ('10', 'NUM'), ('.', '.')], [('The', 'DET'), ('downgrading', 'NOUN'), ('of', 'ADP'), ('debt', 'NOUN'), ('issued', 'VERB'), ('*', 'X'), ('by', 'ADP'), ('CS', 'NOUN'), ('First', 'NOUN'), ('Boston', 'NOUN'), ('Inc.', 'NOUN'), (',', '.'), ('parent', 'NOUN'), ('of', 'ADP'), ('First', 'NOUN'), ('Boston', 'NOUN'), ('Corp.', 'NOUN'), (',', '.'), ('by', 'ADP'), ('Moody', 'NOUN'), (\"'s\", 'PRT'), ('Investors', 'NOUN'), ('Service', 'NOUN'), ('Inc.', 'NOUN'), (',', '.'), ('*', 'X'), ('coupled', 'VERB'), ('*', 'X'), ('with', 'ADP'), ('a', 'DET'), ('Moody', 'NOUN'), (\"'s\", 'PRT'), ('announcement', 'NOUN'), ('that', 'ADP'), ('Shearson', 'NOUN'), ('Lehman', 'NOUN'), ('Hutton', 'NOUN'), ('Holdings', 'NOUN'), ('Inc.', 'NOUN'), ('is', 'VERB'), ('under', 'ADP'), ('review', 'NOUN'), ('for', 'ADP'), ('a', 'DET'), ('possible', 'ADJ'), ('downgrade', 'NOUN'), (',', '.'), ('sent', 'VERB'), ('shivers', 'NOUN'), ('through', 'ADP'), ('the', 'DET'), ('brokerage', 'NOUN'), ('community', 'NOUN'), ('this', 'DET'), ('week', 'NOUN'), ('.', '.')], [('That', 'DET'), ('sounds', 'VERB'), ('neat', 'ADJ'), (',', '.'), ('but', 'CONJ'), ('this', 'DET'), ('government', 'NOUN'), ('--', '.'), ('any', 'DET'), ('government', 'NOUN'), ('--', '.'), ('propagandizes', 'VERB'), ('its', 'PRON'), ('own', 'ADJ'), ('people', 'NOUN'), ('every', 'DET'), ('day', 'NOUN'), ('.', '.')], [('So', 'ADP'), ('far', 'ADV'), (',', '.'), ('Mr.', 'NOUN'), ('Hahn', 'NOUN'), ('is', 'VERB'), ('trying', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('entice', 'VERB'), ('Nekoosa', 'NOUN'), ('into', 'ADP'), ('*', 'X'), ('negotiating', 'VERB'), ('a', 'DET'), ('friendly', 'ADJ'), ('surrender', 'NOUN'), ('while', 'ADP'), ('*-1', 'X'), ('talking', 'VERB'), ('tough', 'ADJ'), ('.', '.')], [('Heritage', 'NOUN'), ('Media', 'NOUN'), ('Corp.', 'NOUN'), (',', '.'), ('New', 'NOUN'), ('York', 'NOUN'), (',', '.'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('offered', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('buy', 'VERB'), ('the', 'DET'), ('shares', 'NOUN'), ('of', 'ADP'), ('POP', 'NOUN'), ('Radio', 'NOUN'), ('Corp.', 'NOUN'), ('0', 'X'), ('it', 'PRON'), ('does', 'VERB'), (\"n't\", 'ADV'), ('already', 'ADV'), ('own', 'VERB'), ('*T*-1', 'X'), ('in', 'ADP'), ('a', 'DET'), ('stock', 'NOUN'), ('swap', 'NOUN'), ('.', '.')], [('The', 'DET'), ('interactions', 'NOUN'), ('between', 'ADP'), ('health', 'NOUN'), ('and', 'CONJ'), ('homelessness', 'NOUN'), ('are', 'VERB'), ('complex', 'ADJ'), (',', '.'), ('*-1', 'X'), ('defying', 'VERB'), ('sweeping', 'ADJ'), ('generalizations', 'NOUN'), ('as', 'ADP'), ('to', 'PRT'), ('``', '.'), ('cause', 'NOUN'), (\"''\", '.'), ('or', 'CONJ'), ('``', '.'), ('effect', 'NOUN'), ('.', '.'), (\"''\", '.')], [('At', 'ADP'), ('the', 'DET'), ('Board', 'NOUN'), ('of', 'ADP'), ('Trade', 'NOUN'), ('yesterday', 'NOUN'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('corn', 'NOUN'), ('contract', 'NOUN'), ('for', 'ADP'), ('December', 'NOUN'), ('delivery', 'NOUN'), ('slipped', 'VERB'), ('3.5', 'NUM'), ('cents', 'NOUN'), ('a', 'DET'), ('bushel', 'NOUN'), ('*-1', 'X'), ('to', 'PRT'), ('settle', 'VERB'), ('at', 'ADP'), ('$', '.'), ('2.375', 'NUM'), ('*U*', 'X'), ('a', 'DET'), ('bushel', 'NOUN'), ('.', '.')], [('It', 'PRON'), ('rose', 'VERB'), ('largely', 'ADV'), ('throughout', 'ADP'), ('the', 'DET'), ('session', 'NOUN'), ('after', 'ADP'), ('*-1', 'X'), ('posting', 'VERB'), ('an', 'DET'), ('intraday', 'NOUN'), ('low', 'ADJ'), ('of', 'ADP'), ('2141.7', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('40', 'NUM'), ('minutes', 'NOUN'), ('of', 'ADP'), ('trading', 'NOUN'), ('.', '.')], [('At', 'ADP'), ('the', 'DET'), ('end', 'NOUN'), ('of', 'ADP'), ('World', 'NOUN'), ('War', 'NOUN'), ('II', 'NOUN'), (',', '.'), ('Germany', 'NOUN'), ('surrendered', 'VERB'), ('before', 'ADP'), ('Japan', 'NOUN'), ('...', '.'), ('.', '.')], [('Then', 'ADV'), ('an', 'DET'), ('announcer', 'NOUN'), ('interjects', 'VERB'), (':', '.'), ('``', '.'), ('It', 'PRON'), ('was', 'VERB'), ('Douglas', 'NOUN'), ('Wilder', 'NOUN'), ('who', 'PRON'), ('*T*-78', 'X'), ('introduced', 'VERB'), ('a', 'DET'), ('bill', 'NOUN'), ('0', 'X'), ('*T*-1', 'X'), ('to', 'PRT'), ('force', 'VERB'), ('rape', 'NOUN'), ('victims', 'NOUN'), ('age', 'NOUN'), ('13', 'NUM'), ('and', 'CONJ'), ('younger', 'ADJ'), ('to', 'PRT'), ('be', 'VERB'), ('interrogated', 'VERB'), ('*-2', 'X'), ('about', 'ADP'), ('their', 'PRON'), ('private', 'ADJ'), ('lives', 'NOUN'), ('by', 'ADP'), ('lawyers', 'NOUN'), ('for', 'ADP'), ('accused', 'VERB'), ('rapists', 'NOUN'), ('.', '.')], [('The', 'DET'), ('concept', 'NOUN'), ('begot', 'VERB'), ('a', 'DET'), ('slew', 'NOUN'), ('of', 'ADP'), ('copycats', 'NOUN'), (',', '.'), ('but', 'CONJ'), ('the', 'DET'), ('banks', 'NOUN'), ('stopped', 'VERB'), ('*-1', 'X'), ('promoting', 'VERB'), ('the', 'DET'), ('packages', 'NOUN'), ('.', '.')], [('Carnival', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-1', 'X'), ('has', 'VERB'), ('three', 'NUM'), ('ships', 'NOUN'), ('on', 'ADP'), ('order', 'NOUN'), ('from', 'ADP'), ('Waertsilae', 'NOUN'), ('Marine', 'NOUN'), (',', '.'), ('presented', 'VERB'), ('claims', 'NOUN'), ('for', 'ADP'), ('$', '.'), ('1.5', 'NUM'), ('billion', 'NUM'), ('*U*', 'X'), ('damages', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('bankruptcy', 'NOUN'), ('court', 'NOUN'), ('this', 'DET'), ('week', 'NOUN'), ('.', '.')], [('Article', 'NOUN'), ('II', 'NOUN'), ('places', 'VERB'), ('on', 'ADP'), ('the', 'DET'), ('president', 'NOUN'), ('the', 'DET'), ('duty', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('nominate', 'VERB'), ('*RNR*-1', 'X'), (',', '.'), ('``', '.'), ('and', 'CONJ'), ('by', 'ADP'), ('and', 'CONJ'), ('with', 'ADP'), ('the', 'DET'), ('Advice', 'NOUN'), ('and', 'CONJ'), ('Consent', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('Senate', 'NOUN'), (\"''\", '.'), ('appoint', 'VERB'), ('*RNR*-1', 'X'), (',', '.'), ('ambassadors', 'NOUN'), (',', '.'), ('judges', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('other', 'ADJ'), ('officers', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('U.S.', 'NOUN'), ('.', '.')], [('Mr.', 'NOUN'), ('Cray', 'NOUN'), (',', '.'), ('who', 'PRON'), ('*T*-1', 'X'), ('could', 'VERB'), (\"n't\", 'ADV'), ('be', 'VERB'), ('reached', 'VERB'), ('*-24', 'X'), ('for', 'ADP'), ('comment', 'NOUN'), (',', '.'), ('will', 'VERB'), ('work', 'VERB'), ('for', 'ADP'), ('the', 'DET'), ('new', 'ADJ'), ('Colorado', 'NOUN'), ('Springs', 'NOUN'), (',', '.'), ('Colo.', 'NOUN'), (',', '.'), ('company', 'NOUN'), ('as', 'ADP'), ('an', 'DET'), ('independent', 'ADJ'), ('contractor', 'NOUN'), ('--', '.'), ('the', 'DET'), ('arrangement', 'NOUN'), ('0', 'X'), ('he', 'PRON'), ('had', 'VERB'), ('*T*-2', 'X'), ('with', 'ADP'), ('Cray', 'NOUN'), ('Research', 'NOUN'), ('.', '.')], [('According', 'VERB'), ('to', 'PRT'), ('Ms.', 'NOUN'), ('Poore', 'NOUN'), (',', '.'), ('Old-House', 'NOUN'), ('Journal', 'NOUN'), ('Corp.', 'NOUN'), (',', '.'), ('her', 'PRON'), ('publishing', 'NOUN'), ('company', 'NOUN'), (',', '.'), ('printed', 'VERB'), ('and', 'CONJ'), ('sold', 'VERB'), ('all', 'DET'), ('126,000', 'NUM'), ('copies', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('premiere', 'NOUN'), ('issue', 'NOUN'), ('.', '.')], [('``', '.'), ('Crime', 'NOUN'), ('was', 'VERB'), ('awful', 'ADJ'), (',', '.'), ('test', 'NOUN'), ('scores', 'NOUN'), ('were', 'VERB'), ('low', 'ADJ'), (',', '.'), ('and', 'CONJ'), ('there', 'DET'), ('was', 'VERB'), ('no', 'DET'), ('enrollment', 'NOUN'), ('in', 'ADP'), ('honors', 'NOUN'), ('programs', 'NOUN'), ('.', '.'), (\"''\", '.')], [('Manufacturers', 'NOUN'), (\"'\", 'PRT'), ('backlogs', 'NOUN'), ('of', 'ADP'), ('unfilled', 'ADJ'), ('orders', 'NOUN'), ('rose', 'VERB'), ('0.5', 'NUM'), ('%', 'NOUN'), ('in', 'ADP'), ('September', 'NOUN'), ('to', 'PRT'), ('$', '.'), ('497.34', 'NUM'), ('billion', 'NUM'), ('*U*', 'X'), (',', '.'), ('*-3', 'X'), ('helped', 'VERB'), ('*-2', 'X'), ('by', 'ADP'), ('strength', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('defense', 'NOUN'), ('capital', 'NOUN'), ('goods', 'NOUN'), ('sector', 'NOUN'), ('.', '.')], [('``', '.'), ('A', 'DET'), ('lot', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('stocks', 'NOUN'), ('that', 'DET'), ('*T*-117', 'X'), ('have', 'VERB'), ('been', 'VERB'), ('under', 'ADP'), ('water', 'NOUN'), ('finally', 'ADV'), ('saw', 'VERB'), ('a', 'DET'), ('reason', 'NOUN'), ('0', 'X'), ('*', 'X'), ('to', 'PRT'), ('uptick', 'VERB'), ('*T*-1', 'X'), (',', '.'), (\"''\", '.'), ('said', 'VERB'), ('*T*-2', 'X'), ('George', 'NOUN'), ('Jennison', 'NOUN'), (',', '.'), ('head', 'ADJ'), ('trader', 'NOUN'), ('of', 'ADP'), ('banking', 'NOUN'), ('issues', 'NOUN'), ('in', 'ADP'), ('Shearson', 'NOUN'), ('Lehman', 'NOUN'), ('Hutton', 'NOUN'), (\"'s\", 'PRT'), ('OTC', 'NOUN'), ('department', 'NOUN'), ('.', '.')], [('Sales', 'NOUN'), ('by', 'ADP'), ('these', 'DET'), ('subsidiaries', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('fiscal', 'ADJ'), ('year', 'NOUN'), ('ending', 'VERB'), ('last', 'ADJ'), ('March', 'NOUN'), ('were', 'VERB'), ('more', 'ADJ'), ('than', 'ADP'), ('$', '.'), ('17', 'NUM'), ('billion', 'NUM'), ('*U*', 'X'), ('.', '.')], [('Temple', 'NOUN'), ('added', 'VERB'), ('that', 'ADP'), ('Sea', 'NOUN'), ('Containers', 'NOUN'), ('is', 'VERB'), ('still', 'ADV'), ('mired', 'VERB'), ('*-2', 'X'), ('in', 'ADP'), ('legal', 'ADJ'), ('problems', 'NOUN'), ('in', 'ADP'), ('Bermuda', 'NOUN'), (',', '.'), ('where', 'ADV'), ('the', 'DET'), ('Supreme', 'NOUN'), ('Court', 'NOUN'), ('has', 'VERB'), ('temporarily', 'ADV'), ('barred', 'VERB'), ('Sea', 'NOUN'), ('Containers', 'NOUN'), ('from', 'ADP'), ('*-3', 'X'), ('buying', 'VERB'), ('back', 'PRT'), ('its', 'PRON'), ('own', 'ADJ'), ('stock', 'NOUN'), ('in', 'ADP'), ('a', 'DET'), ('case', 'NOUN'), ('brought', 'VERB'), ('*', 'X'), ('by', 'ADP'), ('Stena', 'NOUN'), ('and', 'CONJ'), ('Tiphook', 'NOUN'), ('*T*-1', 'X'), ('.', '.')], [('Georgia-Pacific', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-1', 'X'), ('went', 'VERB'), ('down', 'ADP'), ('2', 'NUM'), ('1\\\\/2', 'NUM'), ('Tuesday', 'NOUN'), (',', '.'), ('lost', 'VERB'), ('another', 'DET'), ('1\\\\/2', 'NUM'), ('to', 'PRT'), ('50', 'NUM'), ('3\\\\/8', 'NUM'), ('.', '.')], [('``', '.'), ('Markey', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('we', 'PRON'), ('could', 'VERB'), ('have', 'VERB'), ('done', 'VERB'), ('this', 'DET'), ('in', 'ADP'), ('public', 'NOUN'), (\"''\", '.'), ('because', 'ADP'), ('so', 'ADV'), ('little', 'ADV'), ('sensitive', 'ADJ'), ('information', 'NOUN'), ('was', 'VERB'), ('disclosed', 'VERB'), ('*-132', 'X'), (',', '.'), ('the', 'DET'), ('aide', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('IRAs', 'NOUN'), ('.', '.')], [('Michael', 'NOUN'), ('Kean', 'NOUN'), (',', '.'), ('director', 'NOUN'), ('of', 'ADP'), ('marketing', 'NOUN'), ('for', 'ADP'), ('CTB', 'NOUN'), ('Macmillan\\\\/McGraw', 'NOUN'), (',', '.'), ('the', 'DET'), ('Macmillan\\\\/McGraw', 'NOUN'), ('division', 'NOUN'), ('that', 'DET'), ('*T*-106', 'X'), ('publishes', 'VERB'), ('Learning', 'NOUN'), ('Materials', 'NOUN'), (',', '.'), ('says', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('is', 'VERB'), (\"n't\", 'ADV'), ('aimed', 'VERB'), ('*-1', 'X'), ('at', 'ADP'), ('*', 'X'), ('improving', 'VERB'), ('test', 'NOUN'), ('scores', 'NOUN'), ('.', '.')], [('The', 'DET'), ('other', 'ADJ'), ('concern', 'NOUN'), ('was', 'VERB'), (\"n't\", 'ADV'), ('identified', 'VERB'), ('.', '.')], [('``', '.'), ('If', 'ADP'), ('you', 'PRON'), ('look', 'VERB'), ('at', 'ADP'), ('the', 'DET'), ('third', 'ADJ'), ('quarter', 'NOUN'), ('as', 'ADP'), ('*', 'X'), ('posting', 'VERB'), ('roughly', 'ADV'), ('2.5', 'NUM'), ('%', 'NOUN'), ('growth', 'NOUN'), (',', '.'), ('I', 'PRON'), ('do', 'VERB'), ('see', 'VERB'), ('some', 'DET'), ('slowing', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('fourth', 'ADJ'), ('quarter', 'NOUN'), (',', '.'), (\"''\", '.'), ('agrees', 'VERB'), ('*T*-1', 'X'), ('Kansas', 'NOUN'), ('City', 'NOUN'), ('Fed', 'NOUN'), ('President', 'NOUN'), ('Roger', 'NOUN'), ('Guffey', 'NOUN'), ('.', '.')], [('In', 'ADP'), ('the', 'DET'), ('1990s', 'NOUN'), (',', '.'), ('*-2', 'X'), ('spurred', 'VERB'), ('*-1', 'X'), ('by', 'ADP'), ('rising', 'VERB'), ('labor', 'NOUN'), ('costs', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('strong', 'ADJ'), ('yen', 'NOUN'), (',', '.'), ('these', 'DET'), ('companies', 'NOUN'), ('will', 'VERB'), ('increasingly', 'ADV'), ('turn', 'VERB'), ('themselves', 'PRON'), ('into', 'ADP'), ('multinationals', 'NOUN'), ('with', 'ADP'), ('plants', 'NOUN'), ('around', 'ADP'), ('the', 'DET'), ('world', 'NOUN'), ('.', '.')], [('A', 'DET'), ('program', 'NOUN'), ('trade', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('5', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('of', 'ADP'), ('stock', 'NOUN'), ('typically', 'ADV'), ('earns', 'VERB'), ('a', 'DET'), ('razor-thin', 'ADJ'), ('profit', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('25,000', 'NUM'), ('*U*', 'X'), ('.', '.')], [('We', 'PRON'), (\"'re\", 'VERB'), ('talking', 'VERB'), ('about', 'ADP'), ('years', 'NOUN'), ('ago', 'ADP'), ('before', 'ADP'), ('anyone', 'NOUN'), ('heard', 'VERB'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('having', 'VERB'), ('any', 'DET'), ('questionable', 'ADJ'), ('properties', 'NOUN'), ('.', '.')], [('So', 'ADV'), ('what', 'PRON'), ('*T*-78', 'X'), ('is', 'VERB'), ('next', 'ADJ'), ('for', 'ADP'), ('program', 'NOUN'), ('trading', 'NOUN'), ('?', '.')], [('The', 'DET'), ('energy', 'NOUN'), ('segment', 'NOUN'), (',', '.'), ('with', 'ADP'), ('a', 'DET'), ('15', 'NUM'), ('%', 'NOUN'), ('rise', 'NOUN'), ('in', 'ADP'), ('operating', 'NOUN'), ('profit', 'NOUN'), (',', '.'), ('is', 'VERB'), ('clearly', 'ADV'), ('the', 'DET'), ('company', 'NOUN'), (\"'s\", 'PRT'), ('strongest', 'ADJ'), ('.', '.')], [('However', 'ADV'), (',', '.'), ('third-quarter', 'NOUN'), ('operating', 'NOUN'), ('profit', 'NOUN'), ('fell', 'VERB'), ('14', 'NUM'), ('%', 'NOUN'), (',', '.'), ('as', 'ADP'), ('USX', 'NOUN'), ('sold', 'VERB'), ('sizable', 'ADJ'), ('chunks', 'NOUN'), ('of', 'ADP'), ('its', 'PRON'), ('diversified', 'ADJ'), ('and', 'CONJ'), ('steel', 'NOUN'), ('segments', 'NOUN'), (',', '.'), ('*', 'X'), ('eliminating', 'VERB'), ('income', 'NOUN'), ('from', 'ADP'), ('those', 'DET'), ('operations', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test in a ratio of 95:5\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95745\n"
     ]
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "# converting the list of sents to a list of (word, pos tag) tuples\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "print(len(train_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Over',\n",
       " '50',\n",
       " 'witnesses',\n",
       " ',',\n",
       " 'mostly',\n",
       " 'students',\n",
       " ',',\n",
       " 'were',\n",
       " 'interviewed',\n",
       " '*-1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12059\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADP', 'VERB', 'PRT', 'NUM', '.', 'PRON', 'CONJ', 'DET', 'X', 'ADJ', 'ADV', 'NOUN'}\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can clearly see the unknown tags will be tagged with 'ADP' as it is first in the set when this script was run. The reason is the first sentence used in training data, had first word tagged to ('Although', 'ADP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Develop Viterbi Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. POS Tagging Algorithm - HMM\n",
    "\n",
    "We'll use the HMM algorithm to tag the words. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word. \n",
    "\n",
    "In other words, to every word w, assign the tag t that maximises the likelihood P(t/w). Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t).\n",
    "\n",
    "\n",
    "P(w/t) is basically the probability that given a tag (say NN), what is the probability of it being w (say 'building'). This can be computed by computing the fraction of all NNs which are equal to w, i.e. \n",
    "\n",
    "P(w/t) = count(w, t) / count(t). \n",
    "\n",
    "\n",
    "The term P(t) is the probability of tag t, and in a tagging task, we assume that a tag will depend only on the previous tag. In other words, the probability of a tag being NN will depend only on the previous tag t(n-1). So for e.g. if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun (blue coat, tall building etc.).\n",
    "\n",
    "\n",
    "Given the penn treebank tagged dataset, we can compute the two terms P(w/t) and P(t) and store them in two large matrices. The matrix of P(w/t) will be sparse, since each word will not be seen with most tags ever, and those terms will thus be zero. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " first\n",
      "(27, 6061)\n",
      "(0, 2990)\n",
      "(0, 8288) \n",
      "\n",
      "\n",
      " will\n",
      "(260, 12901)\n",
      "(1, 27471)\n",
      "\n",
      " book\n",
      "(7, 27471)\n",
      "(1, 12901)\n",
      "\n",
      " Android\n",
      "(0, 27471)\n",
      "(0, 12901)\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "\n",
    "# first\n",
    "print(\"\\n\", \"first\")\n",
    "print(word_given_tag('large', 'ADJ'))\n",
    "print(word_given_tag('large', 'ADV'))\n",
    "print(word_given_tag('large', 'DET'), \"\\n\")\n",
    "\n",
    "# will\n",
    "print(\"\\n\", \"will\")\n",
    "print(word_given_tag('will', 'VERB'))\n",
    "print(word_given_tag('will', 'NOUN'))\n",
    "\n",
    "# book\n",
    "print(\"\\n\", \"book\")\n",
    "print(word_given_tag('book', 'NOUN'))\n",
    "print(word_given_tag('book', 'VERB'))\n",
    "\n",
    "# Android\n",
    "print(\"\\n\", \"Android\")\n",
    "print(word_given_tag('Android', 'NOUN'))\n",
    "print(word_given_tag('Android', 'VERB'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4245, 6061)\n",
      "(366, 27471)\n",
      "(7279, 27471)\n",
      "(4013, 27471)\n"
     ]
    }
   ],
   "source": [
    "# examples\n",
    "print(t2_given_t1(t2='NOUN', t1='ADJ'))\n",
    "print(t2_given_t1('DET', 'NOUN'))\n",
    "print(t2_given_t1('NOUN', 'NOUN'))\n",
    "print(t2_given_t1('VERB', 'NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1945, 11169)\n",
      "(999, 11169)\n",
      "(2456, 11169)\n"
     ]
    }
   ],
   "source": [
    "#Please note P(tag|start) is same as P(tag|'.')\n",
    "print(t2_given_t1('DET', '.'))\n",
    "print(t2_given_t1('VERB', '.'))\n",
    "print(t2_given_t1('NOUN', '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADP</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PRT</th>\n",
       "      <th>NUM</th>\n",
       "      <th>.</th>\n",
       "      <th>PRON</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>X</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.017398</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.063187</td>\n",
       "      <td>0.040453</td>\n",
       "      <td>0.067670</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.322660</td>\n",
       "      <td>0.035223</td>\n",
       "      <td>0.106095</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.323407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.089916</td>\n",
       "      <td>0.169909</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.023487</td>\n",
       "      <td>0.034183</td>\n",
       "      <td>0.036121</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.134641</td>\n",
       "      <td>0.218510</td>\n",
       "      <td>0.064801</td>\n",
       "      <td>0.080846</td>\n",
       "      <td>0.110534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.020595</td>\n",
       "      <td>0.401438</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.057862</td>\n",
       "      <td>0.042498</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.097744</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.248774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.035322</td>\n",
       "      <td>0.017216</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>0.184921</td>\n",
       "      <td>0.111903</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.356486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.090787</td>\n",
       "      <td>0.089444</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.080491</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.066255</td>\n",
       "      <td>0.058018</td>\n",
       "      <td>0.174143</td>\n",
       "      <td>0.027039</td>\n",
       "      <td>0.044677</td>\n",
       "      <td>0.052556</td>\n",
       "      <td>0.219894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADP      VERB       PRT       NUM         .      PRON      CONJ  \\\n",
       "ADP   0.017398  0.008219  0.001388  0.063187  0.040453  0.067670  0.000747   \n",
       "VERB  0.089916  0.169909  0.031703  0.023487  0.034183  0.036121  0.005348   \n",
       "PRT   0.020595  0.401438  0.001635  0.057862  0.042498  0.017980  0.002288   \n",
       "NUM   0.035322  0.017216  0.027011  0.184921  0.111903  0.001484  0.013654   \n",
       ".     0.090787  0.089444  0.002507  0.080491  0.094100  0.066255  0.058018   \n",
       "\n",
       "           DET         X       ADJ       ADV      NOUN  \n",
       "ADP   0.322660  0.035223  0.106095  0.013555  0.323407  \n",
       "VERB  0.134641  0.218510  0.064801  0.080846  0.110534  \n",
       "PRT   0.097744  0.013403  0.085976  0.009807  0.248774  \n",
       "NUM   0.003265  0.211636  0.034135  0.002968  0.356486  \n",
       ".     0.174143  0.027039  0.044677  0.052556  0.219894  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAKvCAYAAACvXwjyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xu0rXdZH/rvY0IEpZE7OggUosmQmyByqaR4CBZOpFBujnCHVmRXORwETikBrKelSotIOVSpzeKiQdHgAIG0SOGcQ0BK5cgOBEoQSpqYC4hACAIRIcl6zh9rblmsrDXnu9bec813vfl8xpgja77vXHM/2fnryfd5n191dwAAAGAKvmvVBQAAAMCxoskFAABgMjS5AAAATIYmFwAAgMnQ5AIAADAZmlwAAAAmQ5MLAADAZGhyAQAAmAxNLgAAAJNx/D78Gb0PfwYAAMB2atUFHAvXfumSlfdVN7nNyQfi71KSCwAAwGRocgEAAJgMTS4AAACTsR/P5AIAAHA01q9fdQUHhiQXAACAyZDkAgAAjF2vr7qCA0OSCwAAwGRocgEAAJgM48oAAABjt25ceShJLgAAAJMhyQUAABi5tnhqMEkuAAAAk6HJBQAAYDKMKwMAAIydxVODSXIBAACYDEkuAADA2Fk8NZgkFwAAgMnQ5AIAADAZxpUBAADGbv36VVdwYEhyAQAAmAxJLgAAwNhZPDWYJBcAAIDJ0OQCAAAwGcaVAQAAxm7duPJQklwAAAAmY26SW1W3TfJ3k1zc3V/Zn5IAAADYrC2eGmzHJLeqfjbJRUl+Pcmnquof7VtVAAAAsAfzxpWfm+Tu3f3jSR6Y5EVDv7SqDlXV4ao6vLa2drQ1AgAAwCDzxpW/1d1fTJLuvqSqvnvol3b3WpIj3W0fRX0AAABYPDXYvCb3pKr69zu97+7nLK8sAAAA2L15Te4Ltry/YJmFAAAAwNHascnt7nP2sxAAAAB2YLvyYHPPya2qp1fVR6rqmtnrcFU9bb+KAwAAgN3YMcmdNbPPTfL8JB9JUknuk+QVVZXufuP+lAgAAHAjt379qis4MOYluc9K8pjuPr+7/6q7v9Ld703yuNk9AAAAGJV5Te6J3f3nWy/Orp24rIIAAABgr+ZtV/7GHu8BAABwLFk8Ndi8JveuVfXxba5XkpOXVA8AAADs2dwmd5trleSkJC9eTjkAAADcwLokd6h55+ReduTnqrp3kiclOTPJpUneuvzSAAAAYHfmHSF0apInJHlikquSvDlJdffp+1QbAAAA7Mq8ceVPJflAkkd298VJUlXP25eqAAAA+DaLpwabd4TQ45J8Psn5VfXaqvrJbDyTCwAAAKM075nctyV5W1V9b5JHJ3lekttX1W8meVt3v2efagQAALhxs3hqsHlJbpKku6/p7jd19yOysVn5wiRnLb0yAAAA2KWFTe5m3f3l7j67ux+yrIIAAABgr+YtngIAAGAEuq9fdQkHxq6SXAAAABgzSS4AAMDYOUJoMEkuAAAAk6HJBQAAYDKMKwMAAIydc3IHk+QCAAAwGZJcAACAsbN4ajBJLgAAAJOhyQUAAGAyjCsDAACM3fr1q67gwJDkAgAAMBmaXAAAACbDuDIAAMDY2a48mCQXAACAyZDkAgAAjN26JHcoSS4AAACTockFAABgMowrAwAAjJ3FU4NJcgEAAJgMSS4AAMDYWTw1mCQXAACAydDkAgAAMBnGlQEAAMbOuPJgklwAAAAmQ5ILAAAwct3Xr7qEA0OSCwAAwGRocgEAAJgM48oAAABjZ/HUYJJcAAAAJkOSCwAAMHYtyR1KkgsAAMBkaHIBAACYjF2NK1fVbZJc1d29pHoAAADYyuKpwXZMcqvq71XV+6rqD6vqR6vqE0k+keQvq+qM/SsRAAAAhpk3rvwbSV6W5PeTvDfJz3b39yf5iST/Zt6XVtWhqjpcVYfX1taOWbEAAAAwz7xx5eO7+z1JUlUv7e4PJUl3f6qq5n5pd68lOdLdGm0GAAA4GrYrDzYvyd38t/iNLfc0rgAAAIzOvCT3XlX11SSV5GaznzN7f9OlVwYAAMAGi6cG27HJ7e7j9rMQAAAAOFq7Pie3qm5RVS9ZRjEAAABwNOYdIXTHqlqrqv9cVT9bVd9TVa9M8pkkt9u/EgEAAG7ken31rwNi3jO5b0zy/iRvTXJGkg8luSjJPbv78/tQGwAAAOzKvCb3Vt39L2c/v7uq/jLJ/br7m8svCwAAgL9l8dRg85rcVNUts7FNOUk+n+R7qup7k6S7v7zk2gAAAGBX5jW535fkgny7yU2Sj8z+2UlOXlZRAAAAsBfzjhC68z7WAQAAwE6MKw82b7vyUzb9fNqWe89eZlEAAACwF/POyX3+pp9/fcu9n1lCLQAAAGxn1ccHHaAjhOY1ubXDz9u9BwAAgJWb1+T2Dj9v9x4AAABWbt525R+uqo9nI7X9wdnPmb23WRkAAGC/WDw12Lwm9/wkL0vy2UhuAQAAOADmNbnvSfJrSX4gyZuT/H53X7gvVQEAAPBtB2jx06rt+Exud7+6u388yf+S5MtJfquq/qyqfqmqTt23CgEAAGCgeYunkiTdfVl3v7y7fzTJk5I8JsmfLb0yAAAA2KWFTW5V3aSqHllVb0ryriT/I8njll4ZAAAAG9bXV/9aoKrOqKpPV9XFVXXWDp85s6o+WVUXVdXvbbr+8qr6xOz1+E3X71JV/19Vfaaq3lxVJyyqY8cmt6oeWlVvSHJlkkNJ/ijJD3b347v77Qv/DQEAALhRqKrjkrwmyU8luVuSJ1bV3bZ85pQkL0pyWnffPclzZ9f/YZL7JLl3kgckeUFVnTj7tZcneVV3n5Lk6iTPWFTLvCT3xUn+JMldu/uR3f2m7r5m+L8mAAAAx0Svr/413/2TXNzdl3T3t5Kcm+RRWz7zzCSv6e6rk6S7vzC7frck7+/u62Y958eSnFFVleQhSd4y+9w5SR69qJB5i6dO7+7XdveXF30JAAAAN2p3SHLFpvdXzq5tdmqSU6vqg1X1oao6Y3b9Y0l+qqq+p6puk+T0JHdMcuskX+nu6+Z85w3MO0IIAAAAkiRVdSgbj7Iesdbda0dub/MrveX98UlOSfLgJCcl+UBV3aO731NV90vy35J8MRsTxdcN/M4b0OQCAACM3YDFT8s2a2jXdrh9ZTbS1yNOSvK5bT7zoe6+NsmlVfXpbDS9H+7uX0nyK0kyW0j1mSRfSnKLqjp+luZu9503sHC7MgAAACzw4SSnzLYhn5DkCUnO2/KZt2djFDmzseRTk1xSVcdV1a1n138kyY8keU93d5Lzk/z07PefnuQdiwqR5AIAAHBUuvu6qnp2kncnOS7JG7r7oqp6aZLD3X3e7N7DquqTSa5P8oLuvqqqbpqN0eUk+WqSp2x6DveFSc6tql9O8tEkr19US200x0u19D8AAABgB9s913ngfOMPXrryvupmZ/7Sgfi7NK4MAADAZBhXBgAAGLvlT+BOhiQXAACAydDkAgAAMBnGlQEAAMZuBOfkHhSSXAAAACZDkgsAADB2ktzBJLkAAABMhiYXAACAyTCuDAAAMHZtXHkoSS4AAACTIckFAAAYO4unBpPkAgAAMBmaXAAAACbDuDIAAMDYda+6ggNDkgsAAMBkSHIBAADGzuKpwSS5AAAATIYmFwAAgMkwrgwAADB2xpUHk+QCAAAwGZJcAACAsWtJ7lBzk9yqes9+FQIAAABHa9G48m33pQoAAAA4BhaNK39fVT12p5vd/YfbXa+qQ0kOJcnZZ5+dQ4cO7b1CAACAG7le71WXcGAsbHKTPCJJbXOvk2zb5Hb3WpK1TZ8DAACApVvU5F7W3T+zL5UAAADAUVrU5G6X4AIAALCfnJM72KLFU0/d7mJVHVdVT15CPQAAALBni5rcy6vqRVX1G1X1sNrwvye5JMmZ+1AfAAAAvb761wGxaFz5d5JcneRPkvxskhckOSHJo7r7wiXXBgAAALuyqMk9ubvvmSRV9bokX0pyp+7+2tIrAwAAgF1a1ORee+SH7r6+qi7V4AIAAOwz5+QOtqjJvVdVfTXf3rJ8s03vu7tPXGp1AAAAsAtzm9zuPm6/CgEAAGAHjhAabG6TW1U3TfJzSX4oyceTvKG7r9uPwgAAAGC3Fh0hdE6S+yb570kenuSVS68IAAAA9mjRM7l327Rd+fVJ/nT5JQEAAPAdjCsPtijJ3bxd2ZgyAAAAozZ0u3KysVHZdmUAAID91o4QGsp2ZQAAACZj0bgyAAAAHBiLxpUBAABYNYunBpPkAgAAMBmSXAAAgLFbt3hqKEkuAAAAk6HJBQAAYDKMKwMAAIxdWzw1lCQXAACAydDkAgAAMBnGlQEAAMbOduXBJLkAAABMhiQXAABg5Hrd4qmhJLkAAABMhiYXAACAyTCuDAAAMHYWTw0myQUAAGAyJLkAAABj1xZPDSXJBQAAYDI0uQAAAEyGcWUAAICxs3hqMEkuAAAAkyHJBQAAGLt1i6eGkuQCAAAwGZpcAAAAJsO4MgAAwNhZPDWYJBcAAIDJkOQCAACMXVs8NZQkFwAAgMnQ5AIAADAZxpUBAADGzuKpwSS5AAAATIYkFwAAYOR63eKpoSS5AAAATIYmFwAAgMkwrgwAADB2Fk8NJskFAABgMuYmuVX17+fd7+7nHNtyAAAAYO8WjSv/XJJPJPmDJJ9LUkuvCAAAgO9kXHmwRePKP5BkLcn/muSpSW6S5LzuPqe7z9npl6rqUFUdrqrDa2trx65aAAAAmGNuktvdVyX5j0n+Y1XdIckTk1xUVS/s7t+Z83tr2WiOk8T/cgAAADga7ZzcoQZtV66q+2SjwX1okncluWCZRQEAAMBeLFo89a+SPCLJnyU5N8mLuvu6/SgMAAAAdmtRkvsvklyS5F6z18uqKtlYQNXd/SPLLQ8AAACLp4Zb1OTeZV+qAAAAgGNg0eKpy/arEAAAALbXktzBFj2T+7V853bkTvKlJOcneeFs+zIAAACMwtxzcrv773T3iZte35fkvkkuysbRQgAAADAag44Q2qy7r07yqqp66hLqAQAAYCvjyoPNTXJ3UlU3yR4aZAAAAFimRc/kPnaby7dM8vgkb1lKRQAAAHyn9fVVV3BgLEpjH7nlfSe5Ksmru/udyykJAAAA9mbREUL/ZL8KAQAAgKO1aFz5l+bc7u7+18e4HgAAALayeGqwRePK12xz7XuTPCPJrZNocgEAABiNRePKrzzyc1X9nSS/kOSfJDk3ySt3+j0AAACOIUnuYAuPAaqqWyV5fpInJzknyX1mZ+UCAADAqCx6JvcVSR6bZC3JPbv76/tSFQAAAOzBoiT3/0jyzSS/mOQlVXXkemVj8dSJS6wNAACAJN3GlYda9Ezud+1XIQAAAHC0Fj6TCwAAwIpZPDWYpBYAAIDJ0OQCAAAwGcaVAQAAxs648mCSXAAAACZDkwsAAMBkGFcGAAAYuTauPJgkFwAAgMmQ5AIAAIydJHcwSS4AAACTockFAABgMowrAwAAjN36qgs4OCS5AAAATIYkFwAAYOQcITScJBcAAIDJ0OQCAAAwGcaVAQAAxs648mCSXAAAACZDkgsAADB2jhAaTJILAADAZGhyAQAAmAzjygAAACPnnNzhJLkAAABMhiQXAABg7CyeGkySCwAAwGRocgEAAJgM48oAAAAjZ/HUcJJcAAAAJkOTCwAAwGQYVwYAABg725UHk+QCAAAwGZJcAACAkWtJ7mB7TnKr6vuPZSEAAABwtI5mXPn1O92oqkNVdbiqDq+trR3FHwEAAADD7Xlcubv/4Zx7a0mOdLcOdAIAADgaxpUHs3gKAACAybB4CgAAYOQsnhpOkgsAAMBkaHIBAACYDOPKAAAAY2dceTBJLgAAAJMhyQUAABg5i6eGk+QCAAAwGZpcAAAAJsO4MgAAwMgZVx5OkgsAAMBRq6ozqurTVXVxVZ21w2fOrKpPVtVFVfV7s2unV9WFm15/U1WPnt377aq6dNO9ey+qQ5ILAAAwcmNPcqvquCSvSfLQJFcm+XBVndfdn9z0mVOSvCjJad19dVXdLkm6+/wk95595lZJLk7ynk1f/4LufsvQWiS5AAAAHK37J7m4uy/p7m8lOTfJo7Z85plJXtPdVydJd39hm+/56STv6u6/3mshmlwAAAAWqqpDVXV40+vQptt3SHLFpvdXzq5tdmqSU6vqg1X1oao6Y5s/5glJfn/LtV+pqo9X1auq6rsX1WlcGQAAYOy6Vl1BunstydoOt7crsLe8Pz7JKUkenOSkJB+oqnt091eSpKp+IMk9k7x70++8KMnnk5ww+7NfmOSl8+qU5AIAAHC0rkxyx03vT0ryuW0+847uvra7L03y6Ww0vUecmeRt3X3tkQvd/Re94ZtJfisbY9FzaXIBAABGrtdX/1rgw0lOqaq7VNUJ2Rg7Pm/LZ96e5PQkqarbZGN8+ZJN95+YLaPKs3Q3VVVJHp3kE4sKMa4MAADAUenu66rq2dkYNT4uyRu6+6KqemmSw9193uzew6rqk0muz8bW5KuSpKrunI0k+P1bvvpNVXXbbIxDX5jk5xbVUt1bx6SPuaX/AQAAADtY/cOsx8Dnf+LBK++rvv+P33cg/i4luQAAACPX6weivxwFz+QCAAAwGZpcAAAAJsO4MgAAwMgN2G7MjCQXAACAyZDkAgAAjFy3xVNDSXIBAACYDE0uAAAAk2FcGQAAYOQsnhpOkgsAAMBkSHIBAABGrtctnhpKkgsAAMBkaHIBAACYDOPKAAAAI9e96goODkkuAAAAkyHJBQAAGDmLp4aT5AIAADAZmlwAAAAmw7gyAADAyBlXHk6SCwAAwGRIcgEAAEbOEULDSXIBAACYDE0uAAAAk2FcGQAAYOQsnhpOkgsAAMBkSHIBAABGrluSO5QkFwAAgMnQ5AIAADAZxpUBAABGrtdXXcHBIckFAABgMjS5AAAATIZxZQAAgJFbt115sLlNblXdad797r782JYDAAAAe7coyX1nkk6y+X8bdJLbJrldkuO2+6WqOpTkUJKcffbZOXTo0NFXCgAAcCPlnNzh5ja53X3Pze+r6s5JXpjkHyR52ZzfW0uyduTtUVUIAAAAAw1aPFVVp1TVbyd5V5ILktytu399mYUBAADAbi16JvceSV6S5O5JfjXJM7r7+v0oDAAAgA29blx5qEXP5H4syRXZeDb3/knuX/Xtv9zufs7ySgMAAIDdWdTk/sy+VAEAAMCO2qajwRYtnjrnyM9VdfONS33N0qsCAACAPVi4eKqqfr6qLk9yWZLLq+qyqnrW8ksDAACA3Vm0eOoXkzwwyYO7+5LZtZOTvLqqbtXdv7wPNQIAANyoWTw13KIk96lJHnukwU2S2c9nJnnaMgsDAACA3Vq0eCrd/TfbXPtGVa0vpyQAAAA2W29J7lCLktwrq+ont16sqock+YvllAQAAAB7syjJfU6Sd1TVf01yQZJOcr8kpyV51JJrAwAAgF1ZdITQRVV1jyRPSnL3JJXkj5P80+3GmAEAADj22rjyYEOfyX3D5mtVdVxVPbm737S0ygAAAGCX5j6TW1UnVtWLquo3quqhteHZSY5sWAYAAGDJulf/OigWJbm/k+TqJH+S5JlJ/nmSE5I8qrsvXHJtAAAAsCuLmtyTu/ueSVJVr0vypSR36u6vLb0yAAAA2KVFTe61R37o7uur6lINLgAAwP5yTu5wi5rce1XVV7OxVTlJbrbpfXf3iUutDgAAAHZh0RFCx+1XIQAAAGzPEULDzW1yq+qmSX4uyQ8l+XiSN3T3dftRGAAAAOzW3COEkpyT5L5J/nuShyd55dIrAgAAgD1a9Ezu3TZtV359kj9dfkkAAABsdpDOqV21RUnu5u3KxpQBAAAYtaHblZONjcq2KwMAADBatisDAACMnHNyh1s0rgwAAAAHxqJxZQAAAFbMObnDSXIBAACYDE0uAAAAk2FcGQAAYOQsnhpOkgsAAMBkSHIBAABGrlddwAEiyQUAAGAyNLkAAABMhnFlAACAkbN4ajhJLgAAAJMhyQUAABi5luQOJskFAABgMjS5AAAATIZxZQAAgJFbX3UBB4gkFwAAgMmQ5AIAAIxcx+KpoSS5AAAATIYmFwAAgMkwrgwAADBy673qCg4OSS4AAACTockFAABgMowrAwAAjNy67cqDSXIBAACYDEkuAADAyDkndzhJLgAAAJMxN8mtqlvNuf3N7r7mGNcDAAAAe7ZoXPmCJJ1sm40fX1VJclZ3v+lYFwYAAMCG9VUXcIDMHVfu7rt098mzf2593THJfZK8ZOvvVdWhqjpcVYfX1taWVTsAAAB8h0Xjyneac7u7+4qqeuE2N9aSHOlu+yjqAwAAuNGzeGq4RePK78wNx5U7yW2T3C7Jcd39n5ZUGwAAAOzK3Ca3u++5+X1V3TnJC5P8gyQvW1pVAAAAsAeDzsmtqlOy8eztA5K8MslzuvvaZRYGAADABounhlv0TO49stHc3j3JryZ5Rndfvx+FAQAAwG4tSnI/luSKbDybe/8k958dG5Qk6e7nLK80AAAAEknubixqcn9mX6oAAACAY2DR4qlzjvxcVTffuNTXLL0qAAAA2IPvWvSBqvr5qro8yWVJLq+qy6rqWcsvDQAAgGTjnNxVvw6KuU1uVf1ikkcmeXB337q7b53k9CQ/NbsHAAAAo7HomdynJrlXd//NkQvdfUlVnZmNpVS/vMziAAAASNYPTpC6cgvHlTc3uJuufSMWfAEAADAyi5rcK6vqJ7denF37i+WUBAAAAHuzaFz5OUneUVX/NckFSTrJ/ZKcluRRS64NAACAJOsHaPHTqi1qcr+Z5B8nOTXJ3ZNUkj9O8vokNxhjBgAAgFVa1OT+X0le3N1v2Hyxqu47u/fIZRUGAADAhl51AQfIomdy79zdH996sbsPJ7nzUioCAACAPVrU5N50zr2bHctCAAAA4GgtanI/XFXP3Hqxqp6RjUVUAAAALNn6CF4HxaJncp+b5G1V9eR8u6m9b5ITkjxmmYUBAADAbs1tcrv7L5M8sKpOT3KP2eV3dvd7l14ZAAAA7NKiJDdJ0t3nJzl/ybUAAACwjfVyTu5Qi57JBQAAgANjUJILAADA6jgndzhJLgAAAJOhyQUAAGAyjCsDAMCEHH/CHVZdwqhc963PrrqEY+IgnVO7apJcAAAAJkOSCwAAMHLrThAaTJILAADAZGhyAQAAmAzjygAAACO3HvPKQ0lyAQAAmAxJLgAAwMj1qgs4QCS5AAAATIYmFwAAgMkwrgwAADByzskdTpILAADAZEhyAQAARm591QUcIJJcAAAAJkOTCwAAwGQYVwYAABg55+QOJ8kFAABgMiS5AAAAI+cIoeEkuQAAAEyGJhcAAIDJMK4MAAAwcs7JHU6SCwAAwGRocgEAAJgM48oAAAAjZ1x5uLlJblVpggEAADgwFjWxf5rkPvtRCAAAANtr5+QOtuiZXH+VAAAAHBiLktzbVtXzd7rZ3f9uu+tVdSjJoSQ5++yzc+jQob1XCAAAAAMtanKPS3Lz7DLR7e61JGtH3u6hLgAAAGYsnhpuUZP7F9390n2pBAAAgAOrqs5I8upshKWv6+5/u81nzkzyL7MRhn6su580u36nJK9LcsfZvYd3959X1V2SnJvkVkk+kuSp3f2teXV4JhcAAGDk1kfwmqeqjkvymiQ/leRuSZ5YVXfb8plTkrwoyWndffckz910+41JXtHdd01y/yRfmF1/eZJXdfcpSa5O8oxFf1eLmtx/s6mgu2wp8LGLvhwAAIAbhfsnubi7L5klrecmedSWzzwzyWu6++ok6e4vJMmsGT6+u//v2fWvd/dfV1UleUiSt8x+/5wkj15UyKIm96xNP791y71fXPTlAAAA3CjcIckVm95fObu22alJTq2qD1bVh2bjzUeuf6Wq/rCqPlpVr5glw7dO8pXuvm7Od97Aomdya4eft3sPAADAEoxhm+/mU3Rm1mZLh5Pt+8OtZR+f5JQkD05yUpIPVNU9ZtcflORHk1ye5M1J/nGS8wZ85w0sanJ7h58HfTkAAADTsOUUna2uzMbSqCNOSvK5bT7zoe6+NsmlVfXpbDS9Vyb5aHdfkiRV9fYkfy/JG5LcoqqOn6W5233nDSxqck+uqvOy0ZUf+Tmz93fZ+dcAAAA4VtbHP0f74SSnzHY5fTbJE5I8actn3p7kiUl+u6puk40x5UuSfCXJLavqtt39xWw8h3u4u7uqzk/y09l4xvfpSd6xqJBFTe7mB4V/bcu9re8BAAC4Eeru66rq2UnenY0jhN7Q3RdV1Uuz0bCeN7v3sKr6ZJLrk7ygu69Kkqr6Z0n+39myqQuSvHb21S9Mcm5V/XKSjyZ5/aJaqnvY1HFV3XZW/BeH/6smMdYMAAD75vgTFu7luVG57lufHX8GOsCr7/SUlfdVv3D57x6Iv8u525Vrw/9ZVV9K8qkk/6OqvlhVv7Q/5QEAALDqM3IXnZM7JouOEHpukr+f5H7dfevuvmWSByQ5raqet/TqAAAAYBcWPZP7tCQP7e4vHbnQ3ZdU1VOSvCfJq5ZZHAAAAAcrSV21RUnuTTY3uEfMnsu9yXJKAgAAgL1Z1OR+a4/3AAAAYN8tGle+V1V9dZvrleSmS6gHAACALVa+WvkAmdvkdvdx+1UIAAAAHK1F48oAAABwYCwaVwYAAGDF1mvVFRwcklwAAAAmQ5ILAAAwcs7JHU6SCwAAwGRocgEAAJgM48oAAAAj55zc4SS5AAAATIYkFwAAYOTWZbmDSXIBAACYDEkuAABMyHXf+uyqS4CV0uQCAACMnHNyhzOuDAAAwGRIcgEAAEbO2qnhJLkAAABMhiYXAACAyTCuDAAAMHIWTw0nyQUAAGAyJLkAAAAjt16rruDgkOQCAAAwGZpcAAAAJsO4MgAAwMitOyl3MEkuAAAAkyHJBQAAGDk57nCSXAAAACZDkwsAAMBkGFcGAAAYufVVF3CASHIBAACYDE0uAAAAk2FcGQAAYOSckzucJBcAAIDJkOQCAACMnBx3OEkuAAAAk6HJBQAAYDJ2bHKr6o5z7j1oOeUAAACw1foIXgfFvCT3/VX1z6vdQGv2AAAW90lEQVTqb5/brarbV9XvJvl3yy8NAAAAdmdek/tjSX4wyUer6iFV9QtJ/jTJnyR5wH4UBwAAwMYRQqt+HRQ7NrndfXV3/9Mkr0vy/yR5QZLTuvs13T03ra6qQ1V1uKoOr62tHduKAQAAYAc7HiFUVbdI8vJspLZnJHl4kndV1S9093vnfWl3ryU50t0enJYfAACAA23eObkfSfIfkvxv3X1dkvdU1b2T/Iequqy7n7gvFQIAANzISQ6Hm9fk/kR3X7n5QndfmOSBVfXM5ZYFAAAAu7djk7u1wd1y77XLKQcAAICtDtIRPqs2b7syAAAAHCiaXAAAACZj3jO5AAAAjEBbPTWYJBcAAIDJkOQCAACMnMVTw0lyAQAAmAxNLgAAAJNhXBkAAGDk1i2eGkySCwAAwGRIcgEAAEZOjjucJBcAAIDJ0OQCAAAwGcaVAQAARs7iqeEkuQAAAEyGJhcAAIDJMK4MAAAwcuurLuAAkeQCAAAwGZJcAACAkWuLpwaT5AIAADAZmlwAAAAmw7gyAADAyFk8NZwmFwAAJuTaL12y6hJG5Sa3OXnVJbDPNLkAAAAjZ/HUcJ7JBQAAYDI0uQAAAEyGcWUAAICRs3hqOEkuAAAAkyHJBQAAGLn1tnhqKEkuAAAAk6HJBQAAYDKMKwMAAIycYeXhJLkAAABMhiQXAABg5NZluYNJcgEAAJgMTS4AAACTYVwZAABg5Nq48mCSXAAAACZDkwsAAMBkGFcGAAAYufVVF3CASHIBAACYDEkuAADAyDkndzhJLgAAAJOhyQUAAGAyjCsDAACMnHNyh5PkAgAAMBmSXAAAgJFzhNBwklwAAAAmQ5MLAADAZOw4rlxVv57s+HTzN5P8zyRv6u6vLaMwAAAANnRbPDXUvCT3cJILdnh9KsmpSf5wu1+sqkNVdbiqDq+trR3bigEAAGAHOya53X3Ool+uqj/a4XfXkhzpbv0vBwAAgKOwrq0abO4zuVX19Kr6SFVdM3sdrqqnHbnf3Q9ffokAAAAwzLxncp+W5LlJnp/kI0kqyX2SvKKq0t1v3J8SAQAAYJh55+Q+K8ljuvvPN117b1U9Lsm5STS5AAAA+8A5ucPNG1c+cUuDmySZXTtxWQUBAADAXs1Lcr+xx3sAAAAcQ23x1GDzmty7VtXHt7leSU5eUj0AAACwZ3Ob3G2uVZKTkrx4OeUAAADA3s07J/eyIz9X1b2TPCnJmUkuTfLW5ZcGAABA4pzc3Zh3hNCpSZ6Q5IlJrkry5iTV3afvU20AAACwK/PGlT+V5ANJHtndFydJVT1vX6oCAADgb3VLcoead4TQ45J8Psn5VfXaqvrJbDyTCwAAAKO0Y5Pb3W/r7scn+eEk70vyvCS3r6rfrKqH7VN9AAAAMNi8JDdJ0t3XdPebuvsR2disfGGSs5ZeGQAAAEmS9RG8DoqFTe5m3f3l7j67ux+yrIIAAABgr3bV5AIAAMCYzduuDAAAwAi0c3IHk+QCAAAwGZJcAACAkVuX5A4myQUAAGAyNLkAAABMhnFlAACAkes2rjyUJBcAAIDJkOQCAACMnMVTw0lyAQAAmAxNLgAAAJNhXBkAAGDk2rjyYJpcAACYkJvc5uRVlwArpckFAAAYuXVHCA3mmVwAAAAmQ5MLAADAZBhXBgAAGDnDysNJcgEAAJgMSS4AAMDIrctyB5PkAgAAMBmaXAAAACbDuDIAAMDIGVceTpILAADAZEhyAQAARq5bkjuUJBcAAIDJ0OQCAAAwGcaVAQAARs7iqeEkuQAAAEyGJhcAAIDJMK4MAAAwcm1ceTBJLgAAAJOhyQUAABi57l75a5GqOqOqPl1VF1fVWTt85syq+mRVXVRVv7fl3olV9dmq+o1N1943+84LZ6/bLarDuDIAAABHpaqOS/KaJA9NcmWSD1fVed39yU2fOSXJi5Kc1t1Xb9Ow/usk79/m65/c3YeH1iLJBQAA4GjdP8nF3X1Jd38ryblJHrXlM89M8pruvjpJuvsLR25U1Y8luX2S9xxtIZpcAACAkVtPr/y1wB2SXLHp/ZWza5udmuTUqvpgVX2oqs5Ikqr6riSvTPKCHb77t2ajyv+iqmpRIZpcAAAAFqqqQ1V1eNPr0Obb2/zK1s74+CSnJHlwkicmeV1V3SLJs5L8UXdfkRt6cnffM8mDZq+nLqpzx2dyq+q+u5l7BgAAYDmGLH7ahxrWkqztcPvKJHfc9P6kJJ/b5jMf6u5rk1xaVZ/ORtP740keVFXPSnLzJCdU1de7+6zu/uzsz/7abFHV/ZO8cV6d85Lc11bVZ6rqpVV1t3lfAgAAwI3ah5OcUlV3qaoTkjwhyXlbPvP2JKcnSVXdJhvjy5d095O7+07dfeck/yzJG7v7rKo6fva5VNVNkjwiyScWFbJjk9vdPzr7kuuTvGU2A/3Cqvq7i750c4y9trZTow8AAMAUdPd1SZ6d5N1J/izJH3T3RbPQ9B/NPvbuJFdV1SeTnJ/kBd191Zyv/e4k766qjye5MMlnk7x2US01NPauqntloxs/M8nnu/u0Qb94wzlsAACA/bJwUdFBcK/vf+DK+6qPff6/HYi/y0GLp2bbrm6XjZXO35vki8ssCgAAAPZix8VTSVJVD8rG1qtHZ2P2+dwkz+vuv9qH2gAAAEjSBmQHm7dd+Yokl2ejsf1X3f2X+1YVAAAA7MG8JPfvd/dl+1YJAAAAHKV525Uvq6qnV9VHquqa2etwVT1tPwsEAAC4sVvvXvnroJg3rvy0JM9N8vwkH8nGVrL7JHlFVaW75x7ACwAAAPtt3rjys5I8prv/fNO191bV47LxnK4mFwAAYB9YPDXcvCOETtzS4CZJZtdOXFZBAAAAsFfzmtxv7PEeAAAArMS8ceW7VtXHt7leSU5eUj0AAABscZAWP63a3CZ3m2uV5KQkL15OOQAAALB3Oza5m8/Irap7J3lSkjOTXJrkrcsvDQAAgMTiqd2Yd4TQqUmekOSJSa5K8uYk1d2n71NtAAAAsCvzxpU/leQDSR7Z3RcnSVU9b1+qAgAAgD2Y1+Q+LhtJ7vlV9V+ycTZu7UtVAAAA/C2Lp4bb8Qih7n5bdz8+yQ8neV+S5yW5fVX9ZlU9bJ/qAwAAgMHmnZObJOnua7r7Td39iGxsVr4wyVlLrwwAAAB2qXr5sbdcHQAAWJVJPHJ5ym1/bOV91We+eMGB+LtcmOQCAADAQTFv8RQAAAAjYPHUcJJcAAAAJkOTCwAAwGQYVwYAABi5ts93MEkuAAAAkyHJBQAAGLnu9VWXcGBIcgEAAJgMTS4AAACTYVwZAABg5NYtnhpMkgsAAMBkSHIBAABGrluSO5QkFwAAgMnQ5AIAADAZxpUBAABGzuKp4SS5AAAATIYkFwAAYOQsnhpOkgsAAMBkaHIBAACYDOPKAAAAI7duXHkwSS4AAACTockFAABgMowrAwAAjFw7J3cwSS4AAACTIckFAAAYOefkDifJBQAAYDI0uQAAAEyGcWUAAICRW7d4ajBJLgAAAJMhyQUAABg5i6eGk+QCAAAwGZpcAAAAJsO4MgAAwMitG1cebG6TW1V3mne/uy8/tuUAAADA3i1Kct+ZpJPUpmud5LZJbpfkuCXVBQAAwIzFU8PNfSa3u+/Z3T8y++c9kzwyyQeTfD3Jc3f6vao6VFWHq+rw2trasa0YAAAAdlBD/o9AVZ2S5CVJHpDklUnO6e5rB/4Z/pcDAACwKrX4I+N3y5v/0Mr7qqu/fvGB+Ltc9EzuPbLR3N49ya8meUZ3X78fhQEAALBhXXY42Nwkt6quT3JFNp7NvUFz293PGfBn+K8BAACsyoFIHxf5vpv/4Mr7qr/6+v88EH+XixZPPSOaVAAAgJWyeGq4uU1ud//2PtUBAAAAR23RM7n/Kd+Z5HaSLyU5v7t/d5mFAQAAwG4tGlf+tW2u3SrJU6rqHt191hJqAgAAYJN148qDDTpC6Aa/VHVckgu6+94DPu6/BgAAsCoHYlnSIjf/nrusvK/6+l9feiD+Lhcludvq7uurDsS/HwAAwIHXssPBFj2Te6ttLt8yydOSXLSUigAAAGCPFiW5F2Rj3PhIbNtJrkpyfpKfX2JdAAAA8P+3d+8xdpR1GMe/T1suVVrlTrhIoQSL5VLwRqAICEQwqEAwtIJQQygqRAtCEEVFaxTBWsPdeqE0Cm2VSKABggRqQCEF2kVYQLCA5V6hiBYLvfDzj3lPz/T07O7ZyzmzZ/b5JJueeWfm9J3f7sy8t3mn13p6hdBurcqImZmZmZmZ1eeJpxrX4zO5krYDzgLGk/XkPg5cFRHLm5w3MzMzMzMzs14Z1t1KSQcDD6bFOUDl3biL0jozMzMzMzOzQaPbVwhJegD4SkQsqUmfAPwiIj7ewP/hfnUzMzMzMytKKV4Ls/nmHyi8XvX228vaIpbd9uQCo2sruAAR0QGMak6WzMzMzMzMzPqmp2dyJWnLiHijJnEreq4gm5mZmZmZ2QDwe3Ib11NFdSZwp6RDJY1KP4cBt6d1ZmZmZmZmZoNGT68QmiXpJWA62ezKAJ3ADyPi1mZnzszMzMzMzKw3up14aoC4X93MzMzMzIrSFpMl9WTTzXYuvF61+p0X2iKW3fbkSvpuN6sjIqYPcH7MzMzMzMzM+qyniafeqpP2XuB0YGuyYcxmZmZmZmbWRC0YgVsaDQ9XljQK+DpZBXc+MCMiljewq38bZmZmZmZWlLYYYtuTTTbdqfB61ZrVL7ZFLHvqya28Luhc4GTgeuCA2lcKmZmZmZmZmQ0GPT2TexlwAjAL2CciVrYkV2ZmZmZmZrZe4d24baTb4cqS3gXeAdayYVxFNvHU6Ab+D/8+zMzMzMysKG0xxLYnIwbBcOW1bTJcuRWvEBoUJE2NiFlF52MwcCyqHIsqx6LKscg4DlWORZVjUeVYVDkWVY5FlWNhRRlWdAZaaGrRGRhEHIsqx6LKsahyLDKOQ5VjUeVYVDkWVY5FlWNR5VhYIYZSJdfMzMzMzMxKzpVcMzMzMzMzK42hVMn18wBVjkWVY1HlWFQ5FhnHocqxqHIsqhyLKseiyrGociysEENm4ikzMzMzMzMrv6HUk2tmZmZmZmYlV4pKrqTjJYWkcWl5jKRVkpZIekLSIkmn5bafIulfkjokPS7pjOJy33eSFkr6VE3aNEm3pePvyP2cmtY/J+lRSX+T9GdJu+b2XZe2fUTSYkkHtfqYBlLueB6T9HtJ76mTfquk90vaJxerFZKeTZ/vKvo4+iOdFzNyy+dJujh9ni3pxJrtV6Z/x6R9p+fWbSNpjaQrW5R9G0C9OR9y+4yXdLekpyQ9Lek7kpTWTZH0rqR9c9s/JmlMq4+tryTtIGmupKXpXnCbpD37c9zpGrtNMUfUf7m/h850LzhX0rC07jBJb9bcW07KfX5F0ou55U2LPp5mkLRLukdslZa3TMu79rRvGahvZa5S3Td6E4O07oXKeZT7jg5JHysi/33RXXkiLU+V9GT6WSRpYm7dBtfFdC1ZkD63/b3EBqdSVHKBycB9wKRc2tKI2D8i9krp50j6Um79vIiYABwG/EjS9i3L7cC5kQ2PmbT8Y7Ljn5D7mZPb5vCI2BdYCFyUS1+Vtt0PuDB9TzurHM/ewGrgy3XSVwBnRcSjlVgBtwDnp+UjC8r7QHkHOKGPhe5ngGNzy58HOgckV1aEhs8HAEkjyc6FSyJiT2A/4CDgq7nvfAH4dqsOYCClSusfgYURMTYiPgR8C9ieEh93Ayp/D+OBo4BPA9/Lrb+35t4yL3ftvBaYmVu3uogDaLaIeB64BrgkJV0CzIqIfxaXq5bqS5mrbBqOQUQ8BzwPHFLZMFWOR0XEohbmub+6LE9IOhY4E5gYEePI7i83SNqhwe8u8zXVCtL2lVxJWwAHA6ezcYUPgIh4BjgX+FqddcuBpUA7tsD+AThW0maQtRYCO5JdLBpxP7BTF+tGA2/0M3+Dyb3AHnXSu4tBGawlm/ThnD7suwp4QtJH0vJJwPyBypgVqpHz4QvAXyLiToCI+B9wNvDN3PYLgPGSPtjEvDbL4cCaiLi2khARHcCelPu4G5buj1OBsys92bbeTOBASdOAicCMHrYvhf6WucqgjzGo7ZSYlNLaSXfliQvIOgdeA4iIxcD1pEbTBgyJa6q1VttXcoHjgDsi4ilghaQDuthuMTCuNlHS7sDuwD+al8XmiIjXgUXA0SlpEjAPCGBszZCyQ+p8xdHAzbnlkWnbJ4FfAdPr7NN2JI0AjgEerUkfDhxB1mtTZlcBJ0t6Xx/2nQtMkrQzsA54aUBzZi3Xi/NhPPBwfpuIWApsIWl0SnoXuJSsB7Td7E3N8SVlP+5eSYX1YcB2KemQmnvL2AKzV5iIWAOcT1bZnVbWXus6+lXmKom+xGA+cFy6/kLWaDy3udlsiq7KExtdN4GHUnojhsw11VqnDJXcyVQvFHPTcj21rdAnSeoga0k7MyJWNCl/zZZvHcy3DNYOV743t889kpYDRwI35NIrw9TGkVWA57R56/3I9Dt+CFgG/Lom/XVgK+BPBeWvJSLiP8AcNm5Vrze1em3aHWRDFieTNaBY++rt+SDq/41Qk34DWY/WbgOf5UIM1ePuTv4+UDtceWlhuSreMcDLZA0mQ0Vfy1xl0usYRMQrZI/7HCFpAtkokseamssm6KY8UU/+WtpIeWMoXVOtBUb0vMngJWlr4JPA3pICGE520lxdZ/P9gSdyy/Mi4uzm57LpbgZ+lloSR0bE4gYe1j8ceAuYDfyAbEjNBiLi/vTcxbbA8oHMcAutSs+J1U1PLZELyIbTXN7arLXcz8lala/Lpb0ObFlZSJOovJbfKSJWS3oY+AZZi+xnmp9Va5Leng+dwCfyG6aRLysj4r+V9q+IWJsmI7mgqbkfeJ3AiV2kl/m4eyUd+zqy+8BeBWdn0EgVlaOAA4H7JM2NiJcLzlZT9bPMVQr9jEGlU+JV2m+ocl698sTjwIeBu3NpB6R0qJY3KmWMeuWNIXFNtdZp957cE4E5EbFrRIyJiF2AZ4Gd8xulSt9PgStansMmi4iVZBNI/YZeXDQjYhUwDTg1VW42kCZFGE52YSqliHiTrDXyPEmbFJ2fZkojFeaTPUNUsZBsRENlBtQpwD11dp8BXJCGx1tJ1TkffgdMlHQkrJ+I6nKyIWW1ZpONDNm2NbkdEHcDmyk3u76kjwJPU+7jbpikbckmk7oyIrrq3R5y0gina8iGKS8DLiMrY5TdkC9z0b8Y3EQ2kVu7DlUGuixPXAr8JDUCVBqBplCt/C8EvpjWDQdOoX55YzYlvqZaa7V7JXcy2eyYeTeRjekfqzSVO9nJeEVEXFf7BSVxI9kMoPmLZu0zufUm3Xo57VuZGKDyTG4H2dDU0yJiXbMzX6SIWAI8QheTR5TMDGD9rIgRsYBsAqKH0+/8YOq0oEZEZ0Rc37JcFkzZa2R2LDofRcifD6kh7HPARZL+TvYM74PARq8CSc8jXk71uc1BL1XajgeOUvYKoU7gYrLnzvtz3CPIZiFtV5X7QCdwF3An8P3c+tpncuv1hpfdGcCyiKgM7b8aGCfp0ALz1Ap9LXO1+zmR1+dyZ0T8G3gAeDUinm1VhpuktjxxC1lny1/TvC6/BE7JjW6YDuwh6RFgCdk8OL+t/dJ2vJfY4CU3zpqZmfVf6vnsiIgyz9hu1iuSZgJPR0S9Ib1mZk3R7j25ZmZmhZP0WbKRERcWnRezwULS7cC+ZI8/mJm1jHtyzczMzMzMrDTck2tmZmZmZmal4UqumZmZmZmZlYYruWZmZmZmZlYaruSamZmZmZlZabiSa2ZmZmZmZqXhSq6ZmZmZmZmVxv8BlAm5Gf9DTuwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_frequent = tags_df[tags_df>0.5]\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_frequent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please note here ADP has been assigned as default tag for unknown words as explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('He', 'PRON'),\n",
       "  ('also', 'ADV'),\n",
       "  ('asserted', 'VERB'),\n",
       "  ('that', 'ADP'),\n",
       "  ('exact', 'ADJ'),\n",
       "  ('questions', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('replicated', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('reaction', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('newsroom', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('emotional', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Many', 'ADJ'),\n",
       "  ('banks', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('particularly', 'ADV'),\n",
       "  ('smaller', 'ADJ'),\n",
       "  ('ones', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('were', 'VERB'),\n",
       "  ('slow', 'ADJ'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('computerize', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('could', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('target', 'VERB'),\n",
       "  ('market', 'NOUN'),\n",
       "  ('niches', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-199', 'X'),\n",
       "  ('would', 'VERB'),\n",
       "  ('have', 'VERB'),\n",
       "  ('made', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('programs', 'NOUN'),\n",
       "  ('more', 'ADV'),\n",
       "  ('profitable', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('But', 'CONJ'),\n",
       "  ('with', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('index', 'NOUN'),\n",
       "  ('proving', 'VERB'),\n",
       "  ('somewhat', 'ADV'),\n",
       "  ('better', 'ADJ'),\n",
       "  ('than', 'ADP'),\n",
       "  ('*', 'X'),\n",
       "  ('expected', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('widely', 'ADV'),\n",
       "  ('anticipated', 'VERB'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('on', 'ADP'),\n",
       "  ('October', 'NOUN'),\n",
       "  ('employment', 'NOUN'),\n",
       "  ('scheduled', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('arrive', 'VERB'),\n",
       "  ('tomorrow', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stock', 'NOUN'),\n",
       "  ('prices', 'NOUN'),\n",
       "  ('firmed', 'VERB'),\n",
       "  ('only', 'ADV'),\n",
       "  ('modestly', 'ADV'),\n",
       "  ('in', 'ADP'),\n",
       "  ('response', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('then', 'ADV'),\n",
       "  ('faltered', 'VERB'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('House', 'NOUN'),\n",
       "  ('voted', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('boost', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('federal', 'ADJ'),\n",
       "  ('minimum', 'ADJ'),\n",
       "  ('wage', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('first', 'ADJ'),\n",
       "  ('time', 'NOUN'),\n",
       "  ('since', 'ADP'),\n",
       "  ('early', 'ADJ'),\n",
       "  ('1981', 'NUM'),\n",
       "  (',', '.'),\n",
       "  ('*-1', 'X'),\n",
       "  ('casting', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('solid', 'ADJ'),\n",
       "  ('382-37', 'NUM'),\n",
       "  ('vote', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('compromise', 'NOUN'),\n",
       "  ('measure', 'NOUN'),\n",
       "  ('backed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('by', 'ADP'),\n",
       "  ('President', 'NOUN'),\n",
       "  ('Bush', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on entire test dataset would take more time. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  21.749807834625244\n",
      "[('He', 'PRON'), ('also', 'ADV'), ('asserted', 'VERB'), ('that', 'DET'), ('exact', 'ADJ'), ('questions', 'NOUN'), ('were', 'VERB'), (\"n't\", 'ADV'), ('replicated', 'ADP'), ('*-1', 'X'), ('.', '.'), ('The', 'DET'), ('reaction', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('newsroom', 'NOUN'), ('was', 'VERB'), ('emotional', 'ADP'), ('.', '.'), ('Many', 'ADJ'), ('banks', 'NOUN'), (',', '.'), ('particularly', 'ADV'), ('smaller', 'ADJ'), ('ones', 'NOUN'), (',', '.'), ('were', 'VERB'), ('slow', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('computerize', 'ADP'), ('and', 'CONJ'), ('could', 'VERB'), (\"n't\", 'ADV'), ('target', 'VERB'), ('market', 'NOUN'), ('niches', 'ADP'), ('that', 'DET'), ('*T*-199', 'ADP'), ('would', 'VERB'), ('have', 'VERB'), ('made', 'VERB'), ('the', 'DET'), ('programs', 'NOUN'), ('more', 'ADV'), ('profitable', 'ADJ'), ('.', '.'), ('But', 'CONJ'), ('with', 'ADP'), ('the', 'DET'), ('index', 'NOUN'), ('proving', 'VERB'), ('somewhat', 'ADV'), ('better', 'ADV'), ('than', 'ADP'), ('*', 'X'), ('expected', 'VERB'), ('and', 'CONJ'), ('the', 'DET'), ('widely', 'ADV'), ('anticipated', 'VERB'), ('report', 'VERB'), ('on', 'ADP'), ('October', 'NOUN'), ('employment', 'NOUN'), ('scheduled', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('arrive', 'ADP'), ('tomorrow', 'NOUN'), (',', '.'), ('stock', 'NOUN'), ('prices', 'NOUN'), ('firmed', 'ADP'), ('only', 'ADV'), ('modestly', 'ADV'), ('in', 'ADP'), ('response', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('report', 'NOUN'), ('and', 'CONJ'), ('then', 'ADV'), ('faltered', 'ADP'), ('.', '.'), ('The', 'DET'), ('House', 'NOUN'), ('voted', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('boost', 'VERB'), ('the', 'DET'), ('federal', 'ADJ'), ('minimum', 'ADJ'), ('wage', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('time', 'NOUN'), ('since', 'ADP'), ('early', 'ADJ'), ('1981', 'NUM'), (',', '.'), ('*-1', 'X'), ('casting', 'VERB'), ('a', 'DET'), ('solid', 'ADJ'), ('382-37', 'ADP'), ('vote', 'NOUN'), ('for', 'ADP'), ('a', 'DET'), ('compromise', 'NOUN'), ('measure', 'NOUN'), ('backed', 'VERB'), ('*', 'X'), ('by', 'ADP'), ('President', 'NOUN'), ('Bush', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('asserted', 'VERB'), (('that', 'DET'), ('that', 'ADP'))],\n",
       " [(\"n't\", 'ADV'), (('replicated', 'ADP'), ('replicated', 'VERB'))],\n",
       " [('was', 'VERB'), (('emotional', 'ADP'), ('emotional', 'ADJ'))],\n",
       " [('were', 'VERB'), (('slow', 'VERB'), ('slow', 'ADJ'))],\n",
       " [('to', 'PRT'), (('computerize', 'ADP'), ('computerize', 'VERB'))],\n",
       " [('market', 'NOUN'), (('niches', 'ADP'), ('niches', 'NOUN'))],\n",
       " [('that', 'DET'), (('*T*-199', 'ADP'), ('*T*-199', 'X'))],\n",
       " [('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))],\n",
       " [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))],\n",
       " [('to', 'PRT'), (('arrive', 'ADP'), ('arrive', 'VERB'))],\n",
       " [('prices', 'NOUN'), (('firmed', 'ADP'), ('firmed', 'VERB'))],\n",
       " [('then', 'ADV'), (('faltered', 'ADP'), ('faltered', 'VERB'))],\n",
       " [('solid', 'ADJ'), (('382-37', 'ADP'), ('382-37', 'NUM'))]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = len(check)/len(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8907563025210085"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Checking accuracy on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4931"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets run it on the test data set\n",
    "test_run_base = [tup for sent in test_set for tup in sent]\n",
    "\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "len(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  762.1802985668182\n",
      "accuracy= 0.8963699046846482\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "# print(tagged_seq)\n",
    "# print(test_run_base)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('accuracy=',accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the previous section where we took few sentences for POS tagging, few words are tagged to '.' \n",
    "\n",
    "Root cause:\n",
    "When vanilla Viterbi algorithm encouters unknown tags, emission probability of those words would be 0.<br />\n",
    "As a result, state_probability becomes 0 [emission_p * transition_p]<br />\n",
    "The tag assigned from tag list would be '.' as it is the first tag. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First technique using Lexicon method\n",
    "#### Lets assign most common tag to unknown words, this is nothing but lexicon based approach. By default Viterbi algorithm assigns ADP as default as it is the first POS tag. We will find out the most common tag and assign it to the unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADP', 'VERB', 'PRT', 'NUM', '.', 'PRON', 'CONJ', 'DET', 'X', 'ADJ', 'ADV', 'NOUN'}\n"
     ]
    }
   ],
   "source": [
    "# first POS tag is 'ADP'\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 27471), ('VERB', 12901), ('.', 11169), ('ADP', 9369), ('DET', 8288)]\n"
     ]
    }
   ],
   "source": [
    "# Most commonly assigned tag is 'NOUN' tag\n",
    "tag_list = list([pair[1] for pair in train_tagged_words])\n",
    "tag_list_counter=collections.Counter(tag_list)\n",
    "print(tag_list_counter.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic updated with only transition probability if emission probabbility is 0\n",
    "def Viterbi_updated_with_lexicon(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        if pmax == 0:\n",
    "            state_max = 'NOUN'\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)]\n",
    "            \n",
    "        # getting state for which probability is maximum\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('He', 'PRON'),\n",
       "  ('also', 'ADV'),\n",
       "  ('asserted', 'VERB'),\n",
       "  ('that', 'ADP'),\n",
       "  ('exact', 'ADJ'),\n",
       "  ('questions', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('replicated', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('reaction', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('newsroom', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('emotional', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Many', 'ADJ'),\n",
       "  ('banks', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('particularly', 'ADV'),\n",
       "  ('smaller', 'ADJ'),\n",
       "  ('ones', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('were', 'VERB'),\n",
       "  ('slow', 'ADJ'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('computerize', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('could', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('target', 'VERB'),\n",
       "  ('market', 'NOUN'),\n",
       "  ('niches', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-199', 'X'),\n",
       "  ('would', 'VERB'),\n",
       "  ('have', 'VERB'),\n",
       "  ('made', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('programs', 'NOUN'),\n",
       "  ('more', 'ADV'),\n",
       "  ('profitable', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('But', 'CONJ'),\n",
       "  ('with', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('index', 'NOUN'),\n",
       "  ('proving', 'VERB'),\n",
       "  ('somewhat', 'ADV'),\n",
       "  ('better', 'ADJ'),\n",
       "  ('than', 'ADP'),\n",
       "  ('*', 'X'),\n",
       "  ('expected', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('widely', 'ADV'),\n",
       "  ('anticipated', 'VERB'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('on', 'ADP'),\n",
       "  ('October', 'NOUN'),\n",
       "  ('employment', 'NOUN'),\n",
       "  ('scheduled', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('arrive', 'VERB'),\n",
       "  ('tomorrow', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stock', 'NOUN'),\n",
       "  ('prices', 'NOUN'),\n",
       "  ('firmed', 'VERB'),\n",
       "  ('only', 'ADV'),\n",
       "  ('modestly', 'ADV'),\n",
       "  ('in', 'ADP'),\n",
       "  ('response', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('then', 'ADV'),\n",
       "  ('faltered', 'VERB'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('House', 'NOUN'),\n",
       "  ('voted', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('boost', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('federal', 'ADJ'),\n",
       "  ('minimum', 'ADJ'),\n",
       "  ('wage', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('first', 'ADJ'),\n",
       "  ('time', 'NOUN'),\n",
       "  ('since', 'ADP'),\n",
       "  ('early', 'ADJ'),\n",
       "  ('1981', 'NUM'),\n",
       "  (',', '.'),\n",
       "  ('*-1', 'X'),\n",
       "  ('casting', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('solid', 'ADJ'),\n",
       "  ('382-37', 'NUM'),\n",
       "  ('vote', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('compromise', 'NOUN'),\n",
       "  ('measure', 'NOUN'),\n",
       "  ('backed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('by', 'ADP'),\n",
       "  ('President', 'NOUN'),\n",
       "  ('Bush', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.156716346740723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8907563025210085"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_lexicon(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('asserted', 'VERB'), (('that', 'DET'), ('that', 'ADP'))],\n",
       " [(\"n't\", 'ADV'), (('replicated', 'NOUN'), ('replicated', 'VERB'))],\n",
       " [('was', 'VERB'), (('emotional', 'NOUN'), ('emotional', 'ADJ'))],\n",
       " [('were', 'VERB'), (('slow', 'VERB'), ('slow', 'ADJ'))],\n",
       " [('to', 'PRT'), (('computerize', 'NOUN'), ('computerize', 'VERB'))],\n",
       " [('niches', 'NOUN'), (('that', 'ADP'), ('that', 'DET'))],\n",
       " [('that', 'DET'), (('*T*-199', 'NOUN'), ('*T*-199', 'X'))],\n",
       " [('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))],\n",
       " [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))],\n",
       " [('to', 'PRT'), (('arrive', 'NOUN'), ('arrive', 'VERB'))],\n",
       " [('prices', 'NOUN'), (('firmed', 'NOUN'), ('firmed', 'VERB'))],\n",
       " [('then', 'ADV'), (('faltered', 'NOUN'), ('faltered', 'VERB'))],\n",
       " [('solid', 'ADJ'), (('382-37', 'NOUN'), ('382-37', 'NUM'))]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second technique using Regex on top of Lexicon\n",
    "Here we use regex on words which are tagged to wrong POS tags <br />\n",
    "For eg '341.20' is tagged to 'NOUN' using Lexicon approach as this number is not part of train data, it should be mapped to  'NUM' using Regex<br />\n",
    "For eg words with patterns like '*-166' to be tagged with 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic updated with only transition probability if emission probabbility is 0\n",
    "def Viterbi_updated_with_regex(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        if pmax == 0:\n",
    "            state_max = 'NOUN'\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)]\n",
    "\n",
    "        if bool(re.match('.*\\*.*', words[key])):\n",
    "            state_max = 'X'\n",
    "        \n",
    "        if bool(re.match('^-?[0-9]+(.[0-9]+)?$', words[key])):\n",
    "            state_max = 'NUM'\n",
    "        \n",
    "        \n",
    "        # getting state for which probability is maximum\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('He', 'PRON'),\n",
       "  ('also', 'ADV'),\n",
       "  ('asserted', 'VERB'),\n",
       "  ('that', 'ADP'),\n",
       "  ('exact', 'ADJ'),\n",
       "  ('questions', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('replicated', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('reaction', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('newsroom', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('emotional', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Many', 'ADJ'),\n",
       "  ('banks', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('particularly', 'ADV'),\n",
       "  ('smaller', 'ADJ'),\n",
       "  ('ones', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('were', 'VERB'),\n",
       "  ('slow', 'ADJ'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('computerize', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('could', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('target', 'VERB'),\n",
       "  ('market', 'NOUN'),\n",
       "  ('niches', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-199', 'X'),\n",
       "  ('would', 'VERB'),\n",
       "  ('have', 'VERB'),\n",
       "  ('made', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('programs', 'NOUN'),\n",
       "  ('more', 'ADV'),\n",
       "  ('profitable', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('But', 'CONJ'),\n",
       "  ('with', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('index', 'NOUN'),\n",
       "  ('proving', 'VERB'),\n",
       "  ('somewhat', 'ADV'),\n",
       "  ('better', 'ADJ'),\n",
       "  ('than', 'ADP'),\n",
       "  ('*', 'X'),\n",
       "  ('expected', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('widely', 'ADV'),\n",
       "  ('anticipated', 'VERB'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('on', 'ADP'),\n",
       "  ('October', 'NOUN'),\n",
       "  ('employment', 'NOUN'),\n",
       "  ('scheduled', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('arrive', 'VERB'),\n",
       "  ('tomorrow', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stock', 'NOUN'),\n",
       "  ('prices', 'NOUN'),\n",
       "  ('firmed', 'VERB'),\n",
       "  ('only', 'ADV'),\n",
       "  ('modestly', 'ADV'),\n",
       "  ('in', 'ADP'),\n",
       "  ('response', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('then', 'ADV'),\n",
       "  ('faltered', 'VERB'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('House', 'NOUN'),\n",
       "  ('voted', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('boost', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('federal', 'ADJ'),\n",
       "  ('minimum', 'ADJ'),\n",
       "  ('wage', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('first', 'ADJ'),\n",
       "  ('time', 'NOUN'),\n",
       "  ('since', 'ADP'),\n",
       "  ('early', 'ADJ'),\n",
       "  ('1981', 'NUM'),\n",
       "  (',', '.'),\n",
       "  ('*-1', 'X'),\n",
       "  ('casting', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('solid', 'ADJ'),\n",
       "  ('382-37', 'NUM'),\n",
       "  ('vote', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('compromise', 'NOUN'),\n",
       "  ('measure', 'NOUN'),\n",
       "  ('backed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('by', 'ADP'),\n",
       "  ('President', 'NOUN'),\n",
       "  ('Bush', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.28715467453003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.907563025210084"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_regex(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('asserted', 'VERB'), (('that', 'DET'), ('that', 'ADP'))],\n",
       " [(\"n't\", 'ADV'), (('replicated', 'NOUN'), ('replicated', 'VERB'))],\n",
       " [('was', 'VERB'), (('emotional', 'NOUN'), ('emotional', 'ADJ'))],\n",
       " [('were', 'VERB'), (('slow', 'VERB'), ('slow', 'ADJ'))],\n",
       " [('to', 'PRT'), (('computerize', 'NOUN'), ('computerize', 'VERB'))],\n",
       " [('niches', 'NOUN'), (('that', 'ADP'), ('that', 'DET'))],\n",
       " [('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))],\n",
       " [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))],\n",
       " [('to', 'PRT'), (('arrive', 'NOUN'), ('arrive', 'VERB'))],\n",
       " [('prices', 'NOUN'), (('firmed', 'NOUN'), ('firmed', 'VERB'))],\n",
       " [('then', 'ADV'), (('faltered', 'NOUN'), ('faltered', 'VERB'))]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third technique using Lexicon and  Regex method to tag unknown words\n",
    "Here we use lexicon and regex on words which are tagged to wrong POS tags <br />\n",
    "For eg new words like 'invited' is tagged to 'NOUN' based on Lexicon approach but most of the words ending with 'ed' would be a 'VERB'.<br /> We wil use combination of Lexicon and Regex to map unknown words ending with 'ed' to VERB <br />\n",
    "Similarly we follow same kind of approach to tag unknown words for the words ending with <br />\n",
    "ly -> ADV <br />\n",
    "ing -> VERB <br />\n",
    "ous -> ADJ <br />\n",
    "Please find the analysis below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('VERB', 2667), ('ADJ', 285), ('NOUN', 69), ('ADV', 10), ('NUM', 3)]\n"
     ]
    }
   ],
   "source": [
    "pair_list = list([pair[1] for pair in train_tagged_words if bool(re.match('.*ed$', pair[0])) ])\n",
    "counter=collections.Counter(pair_list)\n",
    "print(counter.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ADV', 839), ('ADJ', 99), ('NOUN', 65), ('VERB', 8)]\n"
     ]
    }
   ],
   "source": [
    "pair_list = list([pair[1] for pair in train_tagged_words if bool(re.match('.*ly$', pair[0])) ])\n",
    "counter=collections.Counter(pair_list)\n",
    "print(counter.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('VERB', 1408), ('NOUN', 789), ('ADJ', 179), ('ADP', 40)]\n"
     ]
    }
   ],
   "source": [
    "pair_list = list([pair[1] for pair in train_tagged_words if bool(re.match('.*ing$', pair[0])) ])\n",
    "counter=collections.Counter(pair_list)\n",
    "print(counter.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ADJ', 83)]\n"
     ]
    }
   ],
   "source": [
    "pair_list = list([pair[1] for pair in train_tagged_words if bool(re.match('.*ous$', pair[0])) ])\n",
    "counter=collections.Counter(pair_list)\n",
    "print(counter.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_updated_with_lexicon_and_regex(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            if emission_p == 0:\n",
    "                state_probability = emission_p * transition_p\n",
    "            else:\n",
    "                state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        \n",
    "        if pmax == 0:\n",
    "            state_max = 'NOUN'\n",
    "            if bool(re.match('.*ed$', words[key])):\n",
    "                state_max = 'VERB'\n",
    "            if bool(re.match('.*ly$', words[key])):\n",
    "                state_max = 'ADV'\n",
    "            if bool(re.match('.*ing$', words[key])):\n",
    "                state_max = 'VERB'\n",
    "            if bool(re.match('.*ous$', words[key])):\n",
    "                state_max = 'ADJ'\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)]\n",
    "            \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('He', 'PRON'),\n",
       "  ('also', 'ADV'),\n",
       "  ('asserted', 'VERB'),\n",
       "  ('that', 'ADP'),\n",
       "  ('exact', 'ADJ'),\n",
       "  ('questions', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('replicated', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('reaction', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('newsroom', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('emotional', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Many', 'ADJ'),\n",
       "  ('banks', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('particularly', 'ADV'),\n",
       "  ('smaller', 'ADJ'),\n",
       "  ('ones', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('were', 'VERB'),\n",
       "  ('slow', 'ADJ'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('computerize', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('could', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('target', 'VERB'),\n",
       "  ('market', 'NOUN'),\n",
       "  ('niches', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-199', 'X'),\n",
       "  ('would', 'VERB'),\n",
       "  ('have', 'VERB'),\n",
       "  ('made', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('programs', 'NOUN'),\n",
       "  ('more', 'ADV'),\n",
       "  ('profitable', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('But', 'CONJ'),\n",
       "  ('with', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('index', 'NOUN'),\n",
       "  ('proving', 'VERB'),\n",
       "  ('somewhat', 'ADV'),\n",
       "  ('better', 'ADJ'),\n",
       "  ('than', 'ADP'),\n",
       "  ('*', 'X'),\n",
       "  ('expected', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('widely', 'ADV'),\n",
       "  ('anticipated', 'VERB'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('on', 'ADP'),\n",
       "  ('October', 'NOUN'),\n",
       "  ('employment', 'NOUN'),\n",
       "  ('scheduled', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('arrive', 'VERB'),\n",
       "  ('tomorrow', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stock', 'NOUN'),\n",
       "  ('prices', 'NOUN'),\n",
       "  ('firmed', 'VERB'),\n",
       "  ('only', 'ADV'),\n",
       "  ('modestly', 'ADV'),\n",
       "  ('in', 'ADP'),\n",
       "  ('response', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('then', 'ADV'),\n",
       "  ('faltered', 'VERB'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('House', 'NOUN'),\n",
       "  ('voted', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('boost', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('federal', 'ADJ'),\n",
       "  ('minimum', 'ADJ'),\n",
       "  ('wage', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('first', 'ADJ'),\n",
       "  ('time', 'NOUN'),\n",
       "  ('since', 'ADP'),\n",
       "  ('early', 'ADJ'),\n",
       "  ('1981', 'NUM'),\n",
       "  (',', '.'),\n",
       "  ('*-1', 'X'),\n",
       "  ('casting', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('solid', 'ADJ'),\n",
       "  ('382-37', 'NUM'),\n",
       "  ('vote', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('compromise', 'NOUN'),\n",
       "  ('measure', 'NOUN'),\n",
       "  ('backed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('by', 'ADP'),\n",
       "  ('President', 'NOUN'),\n",
       "  ('Bush', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.03455090522766\n",
      "[('He', 'PRON'), ('also', 'ADV'), ('asserted', 'VERB'), ('that', 'DET'), ('exact', 'ADJ'), ('questions', 'NOUN'), ('were', 'VERB'), (\"n't\", 'ADV'), ('replicated', 'VERB'), ('*-1', 'X'), ('.', '.'), ('The', 'DET'), ('reaction', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('newsroom', 'NOUN'), ('was', 'VERB'), ('emotional', 'NOUN'), ('.', '.'), ('Many', 'ADJ'), ('banks', 'NOUN'), (',', '.'), ('particularly', 'ADV'), ('smaller', 'ADJ'), ('ones', 'NOUN'), (',', '.'), ('were', 'VERB'), ('slow', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('computerize', 'NOUN'), ('and', 'CONJ'), ('could', 'VERB'), (\"n't\", 'ADV'), ('target', 'VERB'), ('market', 'NOUN'), ('niches', 'NOUN'), ('that', 'ADP'), ('*T*-199', 'NOUN'), ('would', 'VERB'), ('have', 'VERB'), ('made', 'VERB'), ('the', 'DET'), ('programs', 'NOUN'), ('more', 'ADV'), ('profitable', 'ADJ'), ('.', '.'), ('But', 'CONJ'), ('with', 'ADP'), ('the', 'DET'), ('index', 'NOUN'), ('proving', 'VERB'), ('somewhat', 'ADV'), ('better', 'ADV'), ('than', 'ADP'), ('*', 'X'), ('expected', 'VERB'), ('and', 'CONJ'), ('the', 'DET'), ('widely', 'ADV'), ('anticipated', 'VERB'), ('report', 'VERB'), ('on', 'ADP'), ('October', 'NOUN'), ('employment', 'NOUN'), ('scheduled', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('arrive', 'NOUN'), ('tomorrow', 'NOUN'), (',', '.'), ('stock', 'NOUN'), ('prices', 'NOUN'), ('firmed', 'VERB'), ('only', 'ADV'), ('modestly', 'ADV'), ('in', 'ADP'), ('response', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('report', 'NOUN'), ('and', 'CONJ'), ('then', 'ADV'), ('faltered', 'VERB'), ('.', '.'), ('The', 'DET'), ('House', 'NOUN'), ('voted', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('boost', 'VERB'), ('the', 'DET'), ('federal', 'ADJ'), ('minimum', 'ADJ'), ('wage', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('time', 'NOUN'), ('since', 'ADP'), ('early', 'ADJ'), ('1981', 'NUM'), (',', '.'), ('*-1', 'X'), ('casting', 'VERB'), ('a', 'DET'), ('solid', 'ADJ'), ('382-37', 'NOUN'), ('vote', 'NOUN'), ('for', 'ADP'), ('a', 'DET'), ('compromise', 'NOUN'), ('measure', 'NOUN'), ('backed', 'VERB'), ('*', 'X'), ('by', 'ADP'), ('President', 'NOUN'), ('Bush', 'NOUN'), ('.', '.')]\n",
      "[[('asserted', 'VERB'), (('that', 'DET'), ('that', 'ADP'))], [('was', 'VERB'), (('emotional', 'NOUN'), ('emotional', 'ADJ'))], [('were', 'VERB'), (('slow', 'VERB'), ('slow', 'ADJ'))], [('to', 'PRT'), (('computerize', 'NOUN'), ('computerize', 'VERB'))], [('niches', 'NOUN'), (('that', 'ADP'), ('that', 'DET'))], [('that', 'DET'), (('*T*-199', 'NOUN'), ('*T*-199', 'X'))], [('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))], [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))], [('to', 'PRT'), (('arrive', 'NOUN'), ('arrive', 'VERB'))], [('solid', 'ADJ'), (('382-37', 'NOUN'), ('382-37', 'NUM'))]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9159663865546218"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_lexicon_and_regex(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "print(tagged_seq)\n",
    "\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "\n",
    "print(incorrect_tagged_cases)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('asserted', 'VERB'), (('that', 'DET'), ('that', 'ADP'))],\n",
       " [('was', 'VERB'), (('emotional', 'NOUN'), ('emotional', 'ADJ'))],\n",
       " [('were', 'VERB'), (('slow', 'VERB'), ('slow', 'ADJ'))],\n",
       " [('to', 'PRT'), (('computerize', 'NOUN'), ('computerize', 'VERB'))],\n",
       " [('niches', 'NOUN'), (('that', 'ADP'), ('that', 'DET'))],\n",
       " [('that', 'DET'), (('*T*-199', 'NOUN'), ('*T*-199', 'X'))],\n",
       " [('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))],\n",
       " [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))],\n",
       " [('to', 'PRT'), (('arrive', 'NOUN'), ('arrive', 'VERB'))],\n",
       " [('solid', 'ADJ'), (('382-37', 'NOUN'), ('382-37', 'NUM'))]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth technique using all rules\n",
    "#### Here we apply all rules found above to maximise correct POS tagging <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_updated_with_all_rules(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            if emission_p == 0:\n",
    "                state_probability = emission_p * transition_p\n",
    "            else:\n",
    "                state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        \n",
    "        if pmax == 0:\n",
    "            state_max = 'NOUN'\n",
    "            if bool(re.match('.*ed$', words[key])):\n",
    "                state_max = 'VERB'\n",
    "            if bool(re.match('.*ly$', words[key])):\n",
    "                state_max = 'ADV'\n",
    "            if bool(re.match('.*ing$', words[key])):\n",
    "                state_max = 'VERB'\n",
    "            if bool(re.match('.*ous$', words[key])):\n",
    "                state_max = 'ADJ'\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)]\n",
    "        \n",
    "        if bool(re.match('.*\\*.*', words[key])):\n",
    "            state_max = 'X'\n",
    "\n",
    "        if bool(re.match('^-?[0-9]+(.[0-9]+)?$', words[key])):\n",
    "            state_max = 'NUM'\n",
    "            \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('He', 'PRON'),\n",
       "  ('also', 'ADV'),\n",
       "  ('asserted', 'VERB'),\n",
       "  ('that', 'ADP'),\n",
       "  ('exact', 'ADJ'),\n",
       "  ('questions', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('replicated', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('reaction', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('newsroom', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('emotional', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('Many', 'ADJ'),\n",
       "  ('banks', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('particularly', 'ADV'),\n",
       "  ('smaller', 'ADJ'),\n",
       "  ('ones', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('were', 'VERB'),\n",
       "  ('slow', 'ADJ'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('computerize', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('could', 'VERB'),\n",
       "  (\"n't\", 'ADV'),\n",
       "  ('target', 'VERB'),\n",
       "  ('market', 'NOUN'),\n",
       "  ('niches', 'NOUN'),\n",
       "  ('that', 'DET'),\n",
       "  ('*T*-199', 'X'),\n",
       "  ('would', 'VERB'),\n",
       "  ('have', 'VERB'),\n",
       "  ('made', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('programs', 'NOUN'),\n",
       "  ('more', 'ADV'),\n",
       "  ('profitable', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('But', 'CONJ'),\n",
       "  ('with', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('index', 'NOUN'),\n",
       "  ('proving', 'VERB'),\n",
       "  ('somewhat', 'ADV'),\n",
       "  ('better', 'ADJ'),\n",
       "  ('than', 'ADP'),\n",
       "  ('*', 'X'),\n",
       "  ('expected', 'VERB'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('widely', 'ADV'),\n",
       "  ('anticipated', 'VERB'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('on', 'ADP'),\n",
       "  ('October', 'NOUN'),\n",
       "  ('employment', 'NOUN'),\n",
       "  ('scheduled', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('arrive', 'VERB'),\n",
       "  ('tomorrow', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('stock', 'NOUN'),\n",
       "  ('prices', 'NOUN'),\n",
       "  ('firmed', 'VERB'),\n",
       "  ('only', 'ADV'),\n",
       "  ('modestly', 'ADV'),\n",
       "  ('in', 'ADP'),\n",
       "  ('response', 'NOUN'),\n",
       "  ('to', 'PRT'),\n",
       "  ('the', 'DET'),\n",
       "  ('report', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('then', 'ADV'),\n",
       "  ('faltered', 'VERB'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('House', 'NOUN'),\n",
       "  ('voted', 'VERB'),\n",
       "  ('*-1', 'X'),\n",
       "  ('to', 'PRT'),\n",
       "  ('boost', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('federal', 'ADJ'),\n",
       "  ('minimum', 'ADJ'),\n",
       "  ('wage', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('first', 'ADJ'),\n",
       "  ('time', 'NOUN'),\n",
       "  ('since', 'ADP'),\n",
       "  ('early', 'ADJ'),\n",
       "  ('1981', 'NUM'),\n",
       "  (',', '.'),\n",
       "  ('*-1', 'X'),\n",
       "  ('casting', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('solid', 'ADJ'),\n",
       "  ('382-37', 'NUM'),\n",
       "  ('vote', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('compromise', 'NOUN'),\n",
       "  ('measure', 'NOUN'),\n",
       "  ('backed', 'VERB'),\n",
       "  ('*', 'X'),\n",
       "  ('by', 'ADP'),\n",
       "  ('President', 'NOUN'),\n",
       "  ('Bush', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.07944941520691\n",
      "[('He', 'PRON'), ('also', 'ADV'), ('asserted', 'VERB'), ('that', 'DET'), ('exact', 'ADJ'), ('questions', 'NOUN'), ('were', 'VERB'), (\"n't\", 'ADV'), ('replicated', 'VERB'), ('*-1', 'X'), ('.', '.'), ('The', 'DET'), ('reaction', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('newsroom', 'NOUN'), ('was', 'VERB'), ('emotional', 'NOUN'), ('.', '.'), ('Many', 'ADJ'), ('banks', 'NOUN'), (',', '.'), ('particularly', 'ADV'), ('smaller', 'ADJ'), ('ones', 'NOUN'), (',', '.'), ('were', 'VERB'), ('slow', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('computerize', 'NOUN'), ('and', 'CONJ'), ('could', 'VERB'), (\"n't\", 'ADV'), ('target', 'VERB'), ('market', 'NOUN'), ('niches', 'NOUN'), ('that', 'ADP'), ('*T*-199', 'X'), ('would', 'VERB'), ('have', 'VERB'), ('made', 'VERB'), ('the', 'DET'), ('programs', 'NOUN'), ('more', 'ADV'), ('profitable', 'ADJ'), ('.', '.'), ('But', 'CONJ'), ('with', 'ADP'), ('the', 'DET'), ('index', 'NOUN'), ('proving', 'VERB'), ('somewhat', 'ADV'), ('better', 'ADV'), ('than', 'ADP'), ('*', 'X'), ('expected', 'VERB'), ('and', 'CONJ'), ('the', 'DET'), ('widely', 'ADV'), ('anticipated', 'VERB'), ('report', 'VERB'), ('on', 'ADP'), ('October', 'NOUN'), ('employment', 'NOUN'), ('scheduled', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('arrive', 'NOUN'), ('tomorrow', 'NOUN'), (',', '.'), ('stock', 'NOUN'), ('prices', 'NOUN'), ('firmed', 'VERB'), ('only', 'ADV'), ('modestly', 'ADV'), ('in', 'ADP'), ('response', 'NOUN'), ('to', 'PRT'), ('the', 'DET'), ('report', 'NOUN'), ('and', 'CONJ'), ('then', 'ADV'), ('faltered', 'VERB'), ('.', '.'), ('The', 'DET'), ('House', 'NOUN'), ('voted', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('boost', 'VERB'), ('the', 'DET'), ('federal', 'ADJ'), ('minimum', 'ADJ'), ('wage', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('time', 'NOUN'), ('since', 'ADP'), ('early', 'ADJ'), ('1981', 'NUM'), (',', '.'), ('*-1', 'X'), ('casting', 'VERB'), ('a', 'DET'), ('solid', 'ADJ'), ('382-37', 'NUM'), ('vote', 'NOUN'), ('for', 'ADP'), ('a', 'DET'), ('compromise', 'NOUN'), ('measure', 'NOUN'), ('backed', 'VERB'), ('*', 'X'), ('by', 'ADP'), ('President', 'NOUN'), ('Bush', 'NOUN'), ('.', '.')]\n",
      "[[('asserted', 'VERB'), (('that', 'DET'), ('that', 'ADP'))], [('was', 'VERB'), (('emotional', 'NOUN'), ('emotional', 'ADJ'))], [('were', 'VERB'), (('slow', 'VERB'), ('slow', 'ADJ'))], [('to', 'PRT'), (('computerize', 'NOUN'), ('computerize', 'VERB'))], [('niches', 'NOUN'), (('that', 'ADP'), ('that', 'DET'))], [('somewhat', 'ADV'), (('better', 'ADV'), ('better', 'ADJ'))], [('anticipated', 'VERB'), (('report', 'VERB'), ('report', 'NOUN'))], [('to', 'PRT'), (('arrive', 'NOUN'), ('arrive', 'VERB'))]]\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_all_rules(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "print(tagged_seq)\n",
    "\n",
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "\n",
    "print(incorrect_tagged_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9327731092436975"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm\n",
    "\n",
    "Compare the tagging accuacies from the above techniques with vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4931"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets run it on the test data set\n",
    "\n",
    "test_run_base = [tup for sent in test_set for tup in sent]\n",
    "\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "len(test_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  771.5909793376923\n",
      "accuracy= 0.8963699046846482\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('accuracy=',accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Viterbi algorith with Lexicon approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  721.8045008182526\n",
      "accuracy= 0.9316568647333198\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_lexicon(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('accuracy=',accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Viterbi algorithm with Regex on top of Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  730.0147860050201\n",
      "accuracy= 0.9292232812816873\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_regex(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('accuracy=',accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Viterbi algorithm with Lexicon and Regex approach to tag words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  717.0057640075684\n",
      "accuracy= 0.9422023930237274\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_lexicon_and_regex(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('accuracy=',accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of Viterbi algorithm with all rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  726.1684226989746\n",
      "accuracy= 0.939768809572095\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_all_rules(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "# print(tagged_seq)\n",
    "# print(test_run_base)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('accuracy=',accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can observe that accuracy has increased on applying one of the above approaches on Viterbi algorithm. \n",
    "### The final updated Viterbi algorithm with rules tags with accuracy of 95% approximately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. List down cases which were incorrectly tagged by original POS tagger and got corrected by modifications\n",
    "\n",
    "#### Take few lines as testcases from the sample file.\n",
    "#### You can observe when this script is run Viterbi algorithm assigns ADP as default. The reason has been explained in the above section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Case  - Android is a mobile operating system developed by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'ADP'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'ADP'), ('.', '.')]\n",
      "Execution time =  2.498084545135498\n"
     ]
    }
   ],
   "source": [
    "sentence_test = 'Android is a mobile operating system developed by Google.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here the unknown words like 'Android', 'Google' are mapped to '.' These words are mapped to Noun using Lexicon approach on top of Viterbi algorithm. Lets see the mapping after running with Lexicon approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.')]\n",
      "Execution time =  2.5910561084747314\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_lexicon(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second case - Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'ADP'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'ADP'), ('worldwide', 'ADP'), ('on', 'ADP'), ('smartphones', 'ADP'), ('since', 'ADP'), ('2011', 'ADP'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'ADP'), ('.', '.')]\n",
      "Execution time =  4.215083599090576\n"
     ]
    }
   ],
   "source": [
    "sentence_test = 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Here the years 2011, 2013 are mapped to 'ADP' These words are mapped to NUM tag using Regex approach on top of Viterbi algorithm. Lets see the mapping after running with Regex approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.')]\n",
      "Execution time =  4.412796497344971\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_regex(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third case - NASA invited social media users to experience the launch of ICESAT-2 Satellite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NASA', 'ADP'), ('invited', 'ADP'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'ADP'), ('Satellite', 'ADP'), ('.', '.')]\n",
      "Execution time =  3.353898048400879\n"
     ]
    }
   ],
   "source": [
    "sentence_test = 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As there are many new words which have been tagged to '.', lets run this sentence on Viterbi algorithm with only Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n",
      "Execution time =  2.0578770637512207\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_lexicon(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here 'invited' has been tagged with 'NOUN' (based on Lexicon rule) as it was not part of trained tag set. As the word ends with 'ed' , it can be tagged to verb as most of the verbs end with 'ed'. Lets see the mapping after updating Viterbi algorithm with all rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n",
      "Execution time =  3.302835464477539\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_all_rules(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth case - Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Google', 'ADP'), ('and', 'CONJ'), ('Twitter', 'ADP'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'ADP'), ('that', 'DET'), ('gave', 'VERB'), ('Google', 'ADP'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitters', 'ADP'), ('firehose', 'ADP'), ('.', '.')]\n",
      "Execution time =  4.253898620605469\n"
     ]
    }
   ],
   "source": [
    "sentence_test = 'Google and Twitter made a deal in 2015 that gave Google access to Twitter''s firehose.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here Google word has been wrongly tagged to ADP but by using Lexicon approach it has been fixed and 2015 which was mapped to ADP has been mapped correctly to NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitters', 'NOUN'), ('firehose', 'NOUN'), ('.', '.')]\n",
      "Execution time =  4.606783390045166\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_updated_with_all_rules(words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(tagged_seq)\n",
    "print('Execution time = ',difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please note the accuracy of the modified Viterbi algorithm varies each time script is run ranging from 94% to 95% with varying default tag from vanila Viterbi algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
